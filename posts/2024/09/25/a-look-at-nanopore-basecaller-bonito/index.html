<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Look at the Nanopore Basecaller: Bonito | Sparktour's Blog</title><meta name=keywords content="bonito"><meta name=description content="Bonito（中文直译为鲣鱼）是Oxford Nanopore Technology开发的一款basecaller。在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识。"><meta name=author content="sparktour"><link rel=canonical href=https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><link crossorigin=anonymous href=/assets/css/stylesheet.93f625d739f1d6a5c6f20c146bc6a8d26b233492b34b2220c54b12fd46a04ded.css integrity="sha256-k/Yl1znx1qXG8gwUa8ao0msjNJKzSyIgxUsS/UagTe0=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.sparktour.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.sparktour.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.sparktour.me/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.sparktour.me/apple-touch-icon.png><link rel=mask-icon href=https://blog.sparktour.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><link rel=alternate hreflang=en href=https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://blog.sparktour.me/scss/callout.css><link rel=stylesheet href=https://s4.zstatic.net/ajax/libs/disqusjs/3.0.2/styles/disqusjs.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-6EJ4YX1XZ8"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6EJ4YX1XZ8")}</script><meta property="og:url" content="https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"><meta property="og:site_name" content="Sparktour's Blog"><meta property="og:title" content="A Look at the Nanopore Basecaller: Bonito"><meta property="og:description" content="Bonito（中文直译为鲣鱼）是Oxford Nanopore Technology开发的一款basecaller。在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-25T21:00:00+00:00"><meta property="article:modified_time" content="2025-01-11T17:33:54+08:00"><meta property="article:tag" content="Bonito"><meta property="og:image" content="https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg"><meta name=twitter:title content="A Look at the Nanopore Basecaller: Bonito"><meta name=twitter:description content="Bonito（中文直译为鲣鱼）是Oxford Nanopore Technology开发的一款basecaller。在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.sparktour.me/posts/"},{"@type":"ListItem","position":2,"name":"A Look at the Nanopore Basecaller: Bonito","item":"https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Look at the Nanopore Basecaller: Bonito","name":"A Look at the Nanopore Basecaller: Bonito","description":"Bonito（中文直译为鲣鱼）是Oxford Nanopore Technology开发的一款basecaller。在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识。","keywords":["bonito"],"articleBody":" 本文将随笔者的研究进展持续更新。目前计划添加的内容有：\n训练的数据集格式和一些技巧 CRF的原理解释 Bonito Basecaller 概述 Bonito（中文直译为鲣鱼，ont很喜欢拿鱼的名字作为软件包的名字）是Oxford Nanopore Technology开发的一款basecaller框架（使用bonito训练的basecaller权重可以被导出至dorado，guppy等使用）。苦于互联网上对basecaller的定性描述文章较少，笔者在研究这些basecaller的架构和数据流时花费了许多的时间与精力。因此在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识，希望能给后来者一些启发。\n什么是Basecaller？ 简单来讲，Basecaller是一个神经网络，他的输入是纳米孔测序时，碱基通过纳米孔时得到的电流，输出是ATCG碱基以及一些其他的调试信息。在ONT的商业套装中，电流一般被存储为fast5格式（基于hdf5）和近两年推出的pod5格式。不管是哪种格式，存储的数据结构都至少包括了以下的一些信息：\n存储的项目 说明 read_id uuid，用于标识唯一序列用 原始电流（raw） 从放大器中直接输出的采样值，没有单位 scale，offset 放大系数和偏移系数，通过pA_val = scale * (raw + offset)可以得到以pA为单位的电流 metadata 和测序相关的一些信息，如时间，使用的试剂盒，测序flowcell等 有读者可能会注意到，纳米孔测序的电流与语音识别的音频信号有些相似：比如，录入麦克风的声音也是以一维数组存储的；同时，Basecaller输出的ATCG也和语音识别网络（ASR）得到的文字转写（transcript）类似。因此，我们也可以认为纳米孔测序中的Basecaller是一个特殊的ASR网络。\nBonito的架构 本节引用的代码均已列出了具体的github repo和commit，读者可以对照源代码进行阅读。 以下是torchinfo输出的模型架构图（dna_r9.4.1_e8_hac@v3.3, state_len=4），模型的输入为[64,5000](batchsize, current_length)\n========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== Model [64, 1000, 1024] -- ├─Sequential: 1-1 [64, 1000, 1024] -- │ └─Convolution: 2-1 [64, 4, 5000] -- │ │ └─Conv1d: 3-1 [64, 4, 5000] 24 │ │ └─Swish: 3-2 [64, 4, 5000] -- │ └─Convolution: 2-2 [64, 16, 5000] -- │ │ └─Conv1d: 3-3 [64, 16, 5000] 336 │ │ └─Swish: 3-4 [64, 16, 5000] -- │ └─Convolution: 2-3 [64, 384, 1000] -- │ │ └─Conv1d: 3-5 [64, 384, 1000] 117,120 │ │ └─Swish: 3-6 [64, 384, 1000] -- │ └─Permute: 2-4 [1000, 64, 384] -- │ └─LSTM: 2-5 [1000, 64, 384] -- │ │ └─LSTM: 3-7 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-6 [1000, 64, 384] -- │ │ └─LSTM: 3-8 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-7 [1000, 64, 384] -- │ │ └─LSTM: 3-9 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-8 [1000, 64, 384] -- │ │ └─LSTM: 3-10 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-9 [1000, 64, 384] -- │ │ └─LSTM: 3-11 [1000, 64, 384] 1,182,720 │ └─Permute: 2-10 [64, 1000, 384] -- │ └─LinearCRFEncoder: 2-11 [64, 1000, 1024] -- │ │ └─Linear: 3-12 [64, 1000, 1024] 394,240 │ │ └─Tanh: 3-13 [64, 1000, 1024] -- ========================================================================================== Total params: 6,425,320 Trainable params: 6,417,640 Non-trainable params: 7,680 Total mult-adds (G): 386.11 ========================================================================================== Input size (MB): 0.64 Forward/backward pass size (MB): 877.57 Params size (MB): 12.85 Estimated Total Size (MB): 891.06 ========================================================================================== Fig. 1 如Marcus等人文章中的图1所示，bonito（和一些常见的basecaler）的模型结构主要分为三大部份：CNN，LSTM/RNN等Encoder和CTC/CRF等Decoder。\nbonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef rnn_encoder(n_base, state_len, insize=1, first_conv_size=4, stride=5, winlen=19, activation='swish', rnn_type='lstm', features=768, scale=5.0, blank_score=None, expand_blanks=True, num_layers=5, norm=None): rnn = layers[rnn_type] return Serial([ conv(insize, first_conv_size, ks=5, bias=True, activation=activation, norm=norm), conv(first_conv_size, 16, ks=5, bias=True, activation=activation, norm=norm), conv(16, features, ks=winlen, stride=stride, bias=True, activation=activation, norm=norm), Permute([2, 0, 1]), *(rnn(features, features, reverse=(num_layers - i) % 2) for i in range(num_layers)), LinearCRFEncoder( features, n_base, state_len, activation='tanh', scale=scale, blank_score=blank_score, expand_blanks=expand_blanks ) ]) 配置文件（a.k.a config.toml） 以dna_r9.4.1_e8_hac@v3.3 （基于 bonito/bonito/models/configs/dna_r9.4.1@v3.1.toml at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub ）为例：\n[global_norm] # State Length of CRF, determine how many state CRF decoder need to consider state_len = 4 [input] features = 1 [labels] labels = [ \"N\", \"A\", \"C\", \"G\", \"T\",] # labels of bases, N means empty state. [qscore] scale = 0.9356 bias = -0.1721 # bias factor of Q Score [model] package = \"bonito.crf\" # use CRF or CTC at decoder (since bonito v0.4, only CRF is valid) [encoder] scale = 5.0 rnn_type = \"lstm\" winlen = 19 features = 384 activation = \"swish\" stride = 5 # downsample stride blank_score = 2.0 [basecaller] # config when basecalling, don't affect training batchsize = 512 chunksize = 10000 overlap = 500 CNN 电流的一维数组输入后，首先会经过三次卷积以进行特征提取。卷集的实现代码位于此处，可以看到是标准的pytorch卷积实现（Conv1d — PyTorch 2.4 documentation），没有太特殊的地方。但需要注意的是，bonito为了加快运算速度，在第三层卷积设置了stride为5，令信号被下采样了5倍（5000 -\u003e 1000）。最终，卷积层的输出为[64, 384, 1000] (batch, channel, signal_length)\nbonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\n@register class Convolution(Module): def __init__(self, insize, size, winlen, stride=1, padding=0, bias=True, activation=None, norm=None): super().__init__() self.conv = torch.nn.Conv1d(insize, size, winlen, stride=stride, padding=padding, bias=bias) self.activation = layers.get(activation, lambda: activation)() if isinstance(norm, dict): self.norm = from_dict(norm) elif isinstance(norm, str): self.norm = layers[norm](size) else: self.norm = norm def forward(self, x): h = self.conv(x) if self.norm is not None: h = self.norm(h) if self.activation is not None: h = self.activation(h) return h def to_dict(self, include_weights=False): res = { \"insize\": self.conv.in_channels, \"size\": self.conv.out_channels, \"bias\": self.conv.bias is not None, \"winlen\": self.conv.kernel_size[0], \"stride\": self.conv.stride[0], \"padding\": self.conv.padding[0], } if self.activation is not None: res[\"activation\"] = self.activation.name if self.norm is not None: res[\"norm\"] = to_dict(self.norm, include_weights) #simplify default case e.g. norm=\"batchnorm\" if not include_weights and self.norm.name in layers: if res[\"norm\"] == to_dict(layers[self.norm.name](res[\"size\"])): res[\"norm\"] = self.norm.name if include_weights: res['params'] = { 'W': self.conv.weight, 'b': self.conv.bias if self.conv.bias is not None else [] } return res LSTM 经过特征提取后的信号经过一个全连接层，随后会进入LSTM层，以学习信号特征在时间上的关系。这里的LSTM也是基于标准的LSTM — PyTorch 2.4 documentation：\nbonito/bonito/nn.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub\n@register class LSTM(RNNWrapper): def __init__(self, size, insize, bias=True, reverse=False): super().__init__(torch.nn.LSTM, size, insize, bias=bias, reverse=reverse) def to_dict(self, include_weights=False): res = { 'size': self.rnn.hidden_size, 'insize': self.rnn.input_size, 'bias': self.rnn.bias, 'reverse': self.reverse, } if include_weights: res['params'] = { 'iW': self.rnn.weight_ih_l0.reshape(4, self.rnn.hidden_size, self.rnn.input_size), 'sW': self.rnn.weight_hh_l0.reshape(4, self.rnn.hidden_size, self.rnn.hidden_size), 'b': self.rnn.bias_ih_l0.reshape(4, self.rnn.hidden_size) } return res LSTM输出层的形状为[1000, 64, 384](signal_length, batch, channel)\nCRF Encoder 数据在离开LSTM后，会进入一个全连接层，以输出一个用于CRF解码的矩阵。从代码可以看到这个Encoder做的只是把数据进行了一次非线性变换，并且对输出进行了重排。\nbonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\n@register class LinearCRFEncoder(Module): def __init__(self, insize, n_base, state_len, bias=True, scale=None, activation=None, blank_score=None, expand_blanks=True, permute=None): super().__init__() self.scale = scale self.n_base = n_base self.state_len = state_len self.blank_score = blank_score self.expand_blanks = expand_blanks size = (n_base + 1) * n_base**state_len if blank_score is None else n_base**(state_len + 1) self.linear = torch.nn.Linear(insize, size, bias=bias) self.activation = layers.get(activation, lambda: activation)() self.permute = permute def forward(self, x): if self.permute is not None: x = x.permute(*self.permute) scores = self.linear(x) if self.activation is not None: scores = self.activation(scores) if self.scale is not None: scores = scores * self.scale if self.blank_score is not None and self.expand_blanks: T, N, C = scores.shape scores = torch.nn.functional.pad( scores.view(T, N, C // self.n_base, self.n_base), (1, 0, 0, 0, 0, 0, 0, 0), value=self.blank_score ).view(T, N, -1) return scores 整个神经网络带权重的部分到此结束。后面的CRF解码器没有包括任何权重。（因此在训练和推理时，bonito使用了不一样的解码器，后面详细解释）\nCRF Decoder CRF Decoder的核心都位于这个函数中：\nbonito/bonito/crf/basecall.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef compute_scores(model, batch, beam_width=32, beam_cut=100.0, scale=1.0, offset=0.0, blank_score=2.0, reverse=False): \"\"\" Compute scores for model. \"\"\" with torch.inference_mode(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) with torch.cuda.device(scores.device): sequence, qstring, moves = beam_search( scores, beam_width=beam_width, beam_cut=beam_cut, scale=scale, offset=offset, blank_score=blank_score ) return { 'moves': moves, 'qstring': qstring, 'sequence': sequence, } 在compute_scores中，scores就是前述神经网络推理出的矩阵，size为[64, 1000, 1024](batch, current_length, state)，$1024=4^5(4base^{4state+1})$。接着，如果测的是RNA，则将score反过来（这也是为什么RNA训练的时候需要把reference fasta反转）。最后，调用koi（一个ONT开发的，不开源的CRF解码包，下面会详细介绍）的beam_search得到moves（输出第几个采样点解码出了碱基，用于碱基序列和电流的对其参考），qstring（Q score string，以数字编码）和sequence（序列，以数字编码）。\n不开源的koi包和其开源替代 自bonito引入CRF解码开始，bonito就将beam search的函数封装进了一个不开源的ont-koi包，这导致了我们无法了解具体的CRF解码实现。但万幸的是，ont在GitHub - davidcpage/seqdist和GitHub - nanoporetech/fast-ctc-decode: Blitzing Fast CTC Beam Search Decoder这两个repo里包含了一些CRF解码的逻辑，同时，ont还在老版bonito中负责处理duplex的部分用前述的开源代码搭出了一个可用的compute_score的工作流：\nbonito/bonito/cli/duplex.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub\ndef compute_scores(model, batch, reverse=False): with torch.no_grad(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model.encoder(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) betas = model.seqdist.backward_scores(scores.to(torch.float32)) trans, init = model.seqdist.compute_transition_probs(scores, betas) return { 'trans': trans.to(dtype).transpose(0, 1), 'init': init.to(dtype).unsqueeze(1), } def beam_search_duplex(seq1, path1, t1, b1, seq2, path2, t2, b2, alphabet='NACGT', beamsize=5, pad=40, T=0.01): env = build_envelope(t1.shape[0], seq1, path1, t2.shape[0], seq2, path2, padding=pad) return crf_beam_search_duplex( t1, b1, t2, b2, alphabet=alphabet, beam_size=beamsize, beam_cut_threshold=T, envelope=env, ) 笔者同时也参考了Marcus对bonito crf解码的研究，得到了一个利用ont的开源代码实现的compute_score函数。函数主要需要修改两处，列举如下：\n修改backward_scores函数为开源实现（可以用bonito 0.5之前的backward_score实现）： bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\nimport seqdist.sparse from seqdist.ctc_simple import logZ_cupy, viterbi_alignments from seqdist.core import SequenceDist, Max, Log, semiring def backward_scores(self, scores, S: semiring=Log): T, N, _ = scores.shape Ms = scores.reshape(T, N, -1, self.n_base + 1) beta_T = Ms.new_full((N, self.n_base**(self.state_len)), S.one) return seqdist.sparse.bwd_scores_cupy(Ms, self.idx, beta_T, S, K=1) 修改compute_scores函数，记得引入对应的包： from fast_ctc_decode import crf_greedy_search def compute_scores(model, batch, beam_width=32, beam_cut=100.0, scale=1.0, offset=0.0, blank_score=2.0, reverse=False): \"\"\" Compute scores for model. \"\"\" with torch.inference_mode(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) # switch dim 1 \u0026 2 scores_pad = scores.permute(1, 0, 2) # pad score n_base = model.seqdist.n_base T, N, C = scores_pad.shape scores_pad = torch.nn.functional.pad( scores_pad.view(T, N, C // n_base, n_base), (1, 0, 0, 0, 0, 0, 0, 0), value=blank_score ).view(T, N, -1) betas = model.seqdist.backward_scores(scores_pad.to(torch.float32)) trans, init = model.seqdist.compute_transition_probs(scores_pad, betas) trans = trans.to(torch.float32).transpose(0, 1) init = init.to(torch.float32).unsqueeze(1) # offload tracebacks = trans.cpu() init = init.cpu() seq_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') qstring_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') moves_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') for batch_idx in range(N): tracebacks_batch = tracebacks[batch_idx].numpy() # (T, 256, 5) init_batch = init[batch_idx][0].numpy() # (256,) # greedy decode, cef_beam_search dont output qstring seq_batch, path_batch = crf_greedy_search( network_output=tracebacks_batch, init_state=init_batch, alphabet=\"NACGT\", qstring=True, qscale=1, qbias=1 ) # re-encode seq_batch_str = seq_batch[:len(seq_batch) // 2] qstring_batch_str = seq_batch[len(seq_batch) // 2:] seq_as_numbers = np.frombuffer(seq_batch_str.encode(), dtype=np.uint8).copy() qstring_as_numbers = np.frombuffer(qstring_batch_str.encode(), dtype=np.uint8).copy() seq_tensor[batch_idx, path_batch] = torch.from_numpy(seq_as_numbers[:len(path_batch)]) qstring_tensor[batch_idx, path_batch] = torch.from_numpy(qstring_as_numbers[:len(path_batch)]) moves_tensor[batch_idx, path_batch] = 1 return { 'qstring': qstring_tensor, 'sequence': seq_tensor, 'moves': moves_tensor, } 需要注意的是，此处的开源实现将beam_search换成了crf_greedy_search，因此basecaller的准确率可能略有下降，但根据笔者的测试，准确率仅下降约0.3%，笔者认为不完美，但可接受。 此时，得到的qstring，sequence是一个长current_length的矩阵。其中部份index为0（说明这个位置并没有解码出新的碱基），剩下的index则是数字（数字编码的ATCG碱基，或q string分数）。\n拼接basecaller结果和输出字符 由于神经网络的窗口大小有限，在遇到长序列的电流时，电流会按照网络配置中给定的chunksize和overlap拆成一段段的短序列。因此，在完成解码后，得到的qstring，sequence和moves需要经过stitch_results函数重新根据read_id拼接在一起。\n在拼接完后，序列则会经过如path_to_str这样的解码函数被解码回碱基序列/Q Score。最后，经过格式化就可以输出为fastq，或过一次mappy之后即可输出aligned sam/bam文件了。\n训练Bonito 数据集结构 参考bonito 0.8.1的官方文档，我们至少需要三个.npy文件才能构成一个训练basecaller的数据集（假设训练时用的每段电流长度为chunksize）。参考bonito的download.py，目前bonito提供了三个训练数据集，列举如下：\nUrl flowcell https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip dna_r9.4.1 https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip dna_r10.4.1 https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip rna004 每个数据集下载下来并解压都包含三个.npy文件：\nFilename Shape 用途 references.npy (data_length, max_len_of_reference) uint8 存储每个信号chunk对应的序列，用诸如{'A': 1, 'C': 2, 'G': 3, 'T': 4}的规则编码ATCG，余下位置用0填充 reference_lengths.npy (data_length,) uint8 存储每个信号chunk对应的序列的长度（不pad0的部分） chunks.npy (data_length, chunksize) float32 存储每个信号chunk的电流讯号 可选的，数据集文件夹中也可以包含一个名为validation_sets的文件夹，如果存在此文件夹，里面的references.npy，reference_lengths.npy，chunks.npy将作为验证集使用。\n训练相关的命令 # bonito train positional arguments: training_directory optional arguments: -h, --help show this help message and exit --config CONFIG --pretrained PRETRAINED --directory DIRECTORY --device DEVICE --lr LR --seed SEED --epochs EPOCHS --batch BATCH --chunks CHUNKS --valid-chunks VALID_CHUNKS --no-amp -f, --force --restore-optim --nondeterministic --save-optim-every SAVE_OPTIM_EVERY --grad-accum-split GRAD_ACCUM_SPLIT --quantile-grad-clip --num-workers NUM_WORKERS 训练时的loss函数计算 和推理时使用的CRF不同，bonito在训练时，使用的解码器和loss函数并不是先前提到的compute_score函数。\nbonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef decode_batch(self, x): scores = self.seqdist.posteriors(x.to(torch.float32)) + 1e-8 tracebacks = self.seqdist.viterbi(scores.log()).to(torch.int16).T return [self.seqdist.path_to_str(x) for x in tracebacks.cpu().numpy()] 而是用seqdist的viterbi search直接得出了序列，然后跟标准参考序列比较得出了一个准确率。\n训练命令 bonito train \\ --config config.toml \\ # 前面提到的模型config，chunksize等会从数据集里自动读取 --device cuda:0 \\ # 显卡 --epochs 5 # epoch --lr 5e-4 \\ # 学习率 --batch 96 \\ # batchsize --pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0 \\ # 现有模型，可以从ont提供的模型选，或者传入其他模型所在的目录 --directory dataset_dir/ \\ # chunks.npy等所在的文件夹 model_dir/ ","wordCount":"4740","inLanguage":"zh","image":"https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg","datePublished":"2024-09-25T21:00:00Z","dateModified":"2025-01-11T17:33:54+08:00","author":{"@type":"Person","name":"sparktour"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"},"publisher":{"@type":"Organization","name":"Sparktour's Blog","logo":{"@type":"ImageObject","url":"https://blog.sparktour.me/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.sparktour.me/ accesskey=h title="Sparktour's Blog (Alt + H)">Sparktour's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://blog.sparktour.me/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://blog.sparktour.me/archives title=Archive><span>Archive</span></a></li><li><a href=https://blog.sparktour.me/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.sparktour.me/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://blog.sparktour.me/about/ title=About><span>About</span></a></li><li><a href=https://blog.sparktour.me/friends/ title=Friends><span>Friends</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.sparktour.me/>主页</a>&nbsp;»&nbsp;<a href=https://blog.sparktour.me/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">A Look at the Nanopore Basecaller: Bonito</h1><div class=post-description>Bonito（中文直译为鲣鱼）是Oxford Nanopore Technology开发的一款basecaller。在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识。</div><div class=post-meta><span title='2024-09-25 21:00:00 +0000 UTC'>2024-09-25</span>&nbsp;·&nbsp;<span title='2025-01-11 17:33:54 +0800 +0800'>更新于: 2025-01-11</span>&nbsp;·&nbsp;10 分钟&nbsp;·&nbsp;sparktour&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/>English</a></li></ul></div></header><figure class=entry-cover><img loading=eager src=https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg alt="Bonito Fish"><figcaption>Bonito Fish</figcaption></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#bonito-basecaller-%e6%a6%82%e8%bf%b0 aria-label="Bonito Basecaller 概述">Bonito Basecaller 概述</a><ul><li><a href=#%e4%bb%80%e4%b9%88%e6%98%afbasecaller aria-label=什么是Basecaller？>什么是Basecaller？</a></li><li><a href=#bonito%e7%9a%84%e6%9e%b6%e6%9e%84 aria-label=Bonito的架构>Bonito的架构</a><ul><li><a href=#%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6aka-configtoml aria-label="配置文件（a.k.a config.toml）">配置文件（a.k.a config.toml）</a></li><li><a href=#cnn aria-label=CNN>CNN</a></li><li><a href=#lstm aria-label=LSTM>LSTM</a></li><li><a href=#crf-encoder aria-label="CRF Encoder">CRF Encoder</a></li><li><a href=#crf-decoder aria-label="CRF Decoder">CRF Decoder</a><ul><li><a href=#%e4%b8%8d%e5%bc%80%e6%ba%90%e7%9a%84koi%e5%8c%85%e5%92%8c%e5%85%b6%e5%bc%80%e6%ba%90%e6%9b%bf%e4%bb%a3 aria-label=不开源的koi包和其开源替代>不开源的koi包和其开源替代</a></li></ul></li><li><a href=#%e6%8b%bc%e6%8e%a5basecaller%e7%bb%93%e6%9e%9c%e5%92%8c%e8%be%93%e5%87%ba%e5%ad%97%e7%ac%a6 aria-label=拼接basecaller结果和输出字符>拼接basecaller结果和输出字符</a></li></ul></li><li><a href=#%e8%ae%ad%e7%bb%83bonito aria-label=训练Bonito>训练Bonito</a><ul><li><a href=#%e6%95%b0%e6%8d%ae%e9%9b%86%e7%bb%93%e6%9e%84 aria-label=数据集结构>数据集结构</a></li><li><a href=#%e8%ae%ad%e7%bb%83%e7%9b%b8%e5%85%b3%e7%9a%84%e5%91%bd%e4%bb%a4 aria-label=训练相关的命令>训练相关的命令</a></li><li><a href=#%e8%ae%ad%e7%bb%83%e6%97%b6%e7%9a%84loss%e5%87%bd%e6%95%b0%e8%ae%a1%e7%ae%97 aria-label=训练时的loss函数计算>训练时的loss函数计算</a></li><li><a href=#%e8%ae%ad%e7%bb%83%e5%91%bd%e4%bb%a4 aria-label=训练命令>训练命令</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><div class="callout callout-info"><p>本文将随笔者的研究进展持续更新。目前计划添加的内容有：</p><ul><li>训练的数据集格式和一些技巧</li><li>CRF的原理解释</li></ul></div><h1 id=bonito-basecaller-概述>Bonito Basecaller 概述<a hidden class=anchor aria-hidden=true href=#bonito-basecaller-概述>#</a></h1><p><a href=https://github.com/nanoporetech/bonito>Bonito</a>（中文直译为鲣鱼，ont很喜欢拿鱼的名字作为软件包的名字）是<a href=https://nanoporetech.com/>Oxford Nanopore Technology</a>开发的一款<a href=https://nanoporetech.com/platform/technology/basecalling>basecaller</a>框架（使用bonito训练的basecaller权重可以被导出至<a href=https://github.com/nanoporetech/dorado>dorado</a>，<a href=https://nanoporetech.com/document/Guppy-protocol>guppy</a>等使用）。苦于互联网上对basecaller的定性描述文章较少，笔者在研究这些basecaller的架构和数据流时花费了许多的时间与精力。因此在本文中，笔者尽量以通俗易懂的语言，介绍bonito的一些数据流和数据格式等二次开发bonito（甚至是其他的纳米孔测序basecaller）需要了解的一些知识，希望能给后来者一些启发。</p><h2 id=什么是basecaller>什么是Basecaller？<a hidden class=anchor aria-hidden=true href=#什么是basecaller>#</a></h2><p>简单来讲，Basecaller是一个神经网络，他的输入是纳米孔测序时，碱基通过纳米孔时得到的电流，输出是ATCG碱基以及一些其他的调试信息。在ONT的商业套装中，电流一般被存储为<a href=https://medium.com/@shiansu/a-look-at-the-nanopore-fast5-format-f711999e2ff6>fast5</a>格式（基于hdf5）和近两年推出的<a href=https://pod5-file-format.readthedocs.io/en/>pod5</a>格式。不管是哪种格式，存储的数据结构都至少包括了以下的一些信息：</p><table><thead><tr><th>存储的项目</th><th>说明</th></tr></thead><tbody><tr><td>read_id</td><td>uuid，用于标识唯一序列用</td></tr><tr><td>原始电流（raw）</td><td>从放大器中直接输出的采样值，没有单位</td></tr><tr><td>scale，offset</td><td>放大系数和偏移系数，通过<code>pA_val = scale * (raw + offset)</code>可以得到以pA为单位的电流</td></tr><tr><td>metadata</td><td>和测序相关的一些信息，如时间，使用的试剂盒，测序flowcell等</td></tr></tbody></table><p>有读者可能会注意到，纳米孔测序的电流与语音识别的音频信号有些相似：比如，录入麦克风的声音也是以一维数组存储的；同时，Basecaller输出的ATCG也和语音识别网络（<a href=https://en.wikipedia.org/wiki/Speech_recognition>ASR</a>）得到的文字转写（transcript）类似。因此，我们也可以认为纳米孔测序中的Basecaller是一个特殊的ASR网络。</p><h2 id=bonito的架构>Bonito的架构<a hidden class=anchor aria-hidden=true href=#bonito的架构>#</a></h2><div class="callout callout-info">本节引用的代码均已列出了具体的github repo和commit，读者可以对照源代码进行阅读。</div><p>以下是torchinfo输出的模型架构图（<code>dna_r9.4.1_e8_hac@v3.3</code>, <code>state_len=4</code>），模型的输入为<code>[64,5000]</code>(batchsize, current_length)</p><pre tabindex=0><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [64, 1000, 1024]          --
├─Sequential: 1-1                        [64, 1000, 1024]          --
│    └─Convolution: 2-1                  [64, 4, 5000]             --
│    │    └─Conv1d: 3-1                  [64, 4, 5000]             24
│    │    └─Swish: 3-2                   [64, 4, 5000]             --
│    └─Convolution: 2-2                  [64, 16, 5000]            --
│    │    └─Conv1d: 3-3                  [64, 16, 5000]            336
│    │    └─Swish: 3-4                   [64, 16, 5000]            --
│    └─Convolution: 2-3                  [64, 384, 1000]           --
│    │    └─Conv1d: 3-5                  [64, 384, 1000]           117,120
│    │    └─Swish: 3-6                   [64, 384, 1000]           --
│    └─Permute: 2-4                      [1000, 64, 384]           --
│    └─LSTM: 2-5                         [1000, 64, 384]           --
│    │    └─LSTM: 3-7                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-6                         [1000, 64, 384]           --
│    │    └─LSTM: 3-8                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-7                         [1000, 64, 384]           --
│    │    └─LSTM: 3-9                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-8                         [1000, 64, 384]           --
│    │    └─LSTM: 3-10                   [1000, 64, 384]           1,182,720
│    └─LSTM: 2-9                         [1000, 64, 384]           --
│    │    └─LSTM: 3-11                   [1000, 64, 384]           1,182,720
│    └─Permute: 2-10                     [64, 1000, 384]           --
│    └─LinearCRFEncoder: 2-11            [64, 1000, 1024]          --
│    │    └─Linear: 3-12                 [64, 1000, 1024]          394,240
│    │    └─Tanh: 3-13                   [64, 1000, 1024]          --
==========================================================================================
Total params: 6,425,320
Trainable params: 6,417,640
Non-trainable params: 7,680
Total mult-adds (G): 386.11
==========================================================================================
Input size (MB): 0.64
Forward/backward pass size (MB): 877.57
Params size (MB): 12.85
Estimated Total Size (MB): 891.06
==========================================================================================
</code></pre><p><figure><img loading=lazy src=https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs13059-023-02903-2/MediaObjects/13059_2023_2903_Fig1_HTML.png alt="Fig. 1"><figcaption>Fig. 1</figcaption></figure></p><p>如Marcus等人<a href=https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02903-2/>文章</a>中的图1所示，bonito（和一些常见的basecaler）的模型结构主要分为三大部份：CNN，LSTM/RNN等Encoder和CTC/CRF等Decoder。</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L150-L163>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>rnn_encoder</span><span class=p>(</span><span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>insize</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>first_conv_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>winlen</span><span class=o>=</span><span class=mi>19</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;swish&#39;</span><span class=p>,</span> <span class=n>rnn_type</span><span class=o>=</span><span class=s1>&#39;lstm&#39;</span><span class=p>,</span> <span class=n>features</span><span class=o>=</span><span class=mi>768</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>5.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>rnn</span> <span class=o>=</span> <span class=n>layers</span><span class=p>[</span><span class=n>rnn_type</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Serial</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>first_conv_size</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=n>first_conv_size</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=mi>16</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Permute</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=o>*</span><span class=p>(</span><span class=n>rnn</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=p>(</span><span class=n>num_layers</span> <span class=o>-</span> <span class=n>i</span><span class=p>)</span> <span class=o>%</span> <span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_layers</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=n>LinearCRFEncoder</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>features</span><span class=p>,</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>scale</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>blank_score</span><span class=o>=</span><span class=n>blank_score</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=n>expand_blanks</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span></code></pre></div><h3 id=配置文件aka-configtoml>配置文件（a.k.a <code>config.toml</code>）<a hidden class=anchor aria-hidden=true href=#配置文件aka-configtoml>#</a></h3><p>以<code>dna_r9.4.1_e8_hac@v3.3</code> （基于 <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/models/configs/dna_r9.4.1@v3.1.toml>bonito/bonito/models/configs/dna_r9.4.1@v3.1.toml at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a> ）为例：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-toml data-lang=toml><span class=line><span class=cl><span class=p>[</span><span class=nx>global_norm</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c># State Length of CRF, determine how many state CRF decoder need to consider</span>
</span></span><span class=line><span class=cl><span class=nx>state_len</span> <span class=p>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>input</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>features</span> <span class=p>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>labels</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>labels</span> <span class=p>=</span> <span class=p>[</span> <span class=s2>&#34;N&#34;</span><span class=p>,</span> <span class=s2>&#34;A&#34;</span><span class=p>,</span> <span class=s2>&#34;C&#34;</span><span class=p>,</span> <span class=s2>&#34;G&#34;</span><span class=p>,</span> <span class=s2>&#34;T&#34;</span><span class=p>,]</span>
</span></span><span class=line><span class=cl><span class=c># labels of bases, N means empty state.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>qscore</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>scale</span> <span class=p>=</span> <span class=mf>0.9356</span>
</span></span><span class=line><span class=cl><span class=nx>bias</span> <span class=p>=</span> <span class=mf>-0.1721</span>
</span></span><span class=line><span class=cl><span class=c># bias factor of Q Score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>model</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>package</span> <span class=p>=</span> <span class=s2>&#34;bonito.crf&#34;</span>
</span></span><span class=line><span class=cl><span class=c># use CRF or CTC at decoder (since bonito v0.4, only CRF is valid)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>encoder</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>scale</span> <span class=p>=</span> <span class=mf>5.0</span>
</span></span><span class=line><span class=cl><span class=nx>rnn_type</span> <span class=p>=</span> <span class=s2>&#34;lstm&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>winlen</span> <span class=p>=</span> <span class=mi>19</span>
</span></span><span class=line><span class=cl><span class=nx>features</span> <span class=p>=</span> <span class=mi>384</span>
</span></span><span class=line><span class=cl><span class=nx>activation</span> <span class=p>=</span> <span class=s2>&#34;swish&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>stride</span> <span class=p>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=c># downsample stride</span>
</span></span><span class=line><span class=cl><span class=nx>blank_score</span> <span class=p>=</span> <span class=mf>2.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>basecaller</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c># config when basecalling, don&#39;t affect training</span>
</span></span><span class=line><span class=cl><span class=nx>batchsize</span> <span class=p>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl><span class=nx>chunksize</span> <span class=p>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl><span class=nx>overlap</span> <span class=p>=</span> <span class=mi>500</span>
</span></span></code></pre></div><h3 id=cnn>CNN<a hidden class=anchor aria-hidden=true href=#cnn>#</a></h3><p>电流的一维数组输入后，首先会经过三次卷积以进行特征提取。卷集的实现代码位于<a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L221-L266>此处</a>，可以看到是标准的pytorch卷积实现（<a href=https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html>Conv1d — PyTorch 2.4 documentation</a>），没有太特殊的地方。但需要注意的是，bonito为了加快运算速度，在第三层卷积设置了stride为5，令信号被下采样了5倍（5000 -> 1000）。最终，卷积层的输出为<code>[64, 384, 1000]</code> (batch, channel, signal_length)</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L221-L266>bonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Convolution</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv1d</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>padding</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>layers</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>activation</span><span class=p>,</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>activation</span><span class=p>)()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>norm</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>from_dict</span><span class=p>(</span><span class=n>norm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>norm</span><span class=p>,</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>layers</span><span class=p>[</span><span class=n>norm</span><span class=p>](</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>norm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>h</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>include_weights</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;insize&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>in_channels</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;size&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>out_channels</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;bias&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;winlen&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>kernel_size</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;stride&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>stride</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;padding&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>padding</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s2>&#34;activation&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>,</span> <span class=n>include_weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1>#simplify default case e.g. norm=&#34;batchnorm&#34;</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>include_weights</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span> <span class=ow>in</span> <span class=n>layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>to_dict</span><span class=p>(</span><span class=n>layers</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span><span class=p>](</span><span class=n>res</span><span class=p>[</span><span class=s2>&#34;size&#34;</span><span class=p>])):</span>
</span></span><span class=line><span class=cl>                    <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>include_weights</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;W&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span></code></pre></div><h3 id=lstm>LSTM<a hidden class=anchor aria-hidden=true href=#lstm>#</a></h3><p>经过特征提取后的信号经过一个全连接层，随后会进入LSTM层，以学习信号特征在时间上的关系。这里的LSTM也是基于标准的<a href=https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>LSTM — PyTorch 2.4 documentation</a>：</p><p><a href=https://github.com/nanoporetech/bonito/blob/91fb1408398fb3d8188621f1486281a2baa76318/bonito/nn.py#L194-L214>bonito/bonito/nn.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LSTM</span><span class=p>(</span><span class=n>RNNWrapper</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=n>reverse</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>include_weights</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;size&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;insize&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>input_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;bias&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;reverse&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>reverse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>include_weights</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;iW&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>weight_ih_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>input_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;sW&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>weight_hh_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;b&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>bias_ih_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span></code></pre></div><p>LSTM输出层的形状为<code>[1000, 64, 384]</code>(signal_length, batch, channel)</p><h3 id=crf-encoder>CRF Encoder<a hidden class=anchor aria-hidden=true href=#crf-encoder>#</a></h3><p>数据在离开LSTM后，会进入一个全连接层，以输出一个用于CRF解码的矩阵。从代码可以看到这个Encoder做的只是把数据进行了一次非线性变换，并且对输出进行了重排。</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L268-L299>bonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LinearCRFEncoder</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>permute</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span> <span class=o>=</span> <span class=n>n_base</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>state_len</span> <span class=o>=</span> <span class=n>state_len</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span> <span class=o>=</span> <span class=n>blank_score</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>expand_blanks</span> <span class=o>=</span> <span class=n>expand_blanks</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=p>(</span><span class=n>n_base</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>n_base</span><span class=o>**</span><span class=n>state_len</span> <span class=k>if</span> <span class=n>blank_score</span> <span class=ow>is</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>n_base</span><span class=o>**</span><span class=p>(</span><span class=n>state_len</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>layers</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>activation</span><span class=p>,</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>activation</span><span class=p>)()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>permute</span> <span class=o>=</span> <span class=n>permute</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>permute</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=o>*</span><span class=bp>self</span><span class=o>.</span><span class=n>permute</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>scores</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>expand_blanks</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>scores</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>value</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>scores</span>
</span></span></code></pre></div><p><strong>整个神经网络带权重的部分到此结束。后面的CRF解码器没有包括任何权重。</strong>（因此在训练和推理时，bonito使用了不一样的解码器，后面详细解释）</p><h3 id=crf-decoder>CRF Decoder<a hidden class=anchor aria-hidden=true href=#crf-decoder>#</a></h3><p>CRF Decoder的核心都位于这个函数中：</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/basecall.py#L27-L47>bonito/bonito/crf/basecall.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=mf>100.0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Compute scores for model.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>sequence</span><span class=p>,</span> <span class=n>qstring</span><span class=p>,</span> <span class=n>moves</span> <span class=o>=</span> <span class=n>beam_search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>scores</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=n>beam_width</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=n>beam_cut</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>scale</span><span class=o>=</span><span class=n>scale</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=n>offset</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;moves&#39;</span><span class=p>:</span> <span class=n>moves</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;qstring&#39;</span><span class=p>:</span> <span class=n>qstring</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;sequence&#39;</span><span class=p>:</span> <span class=n>sequence</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></div><p>在<code>compute_scores</code>中，<code>scores</code>就是前述神经网络推理出的矩阵，size为<code>[64, 1000, 1024]</code>(batch, current_length, state)，$1024=4^5(4base^{4state+1})$。接着，如果测的是RNA，则将score反过来（这也是为什么RNA训练的时候需要把reference fasta反转）。最后，调用<a href=https://pypi.org/project/ont-koi/>koi</a>（一个ONT开发的，不开源的CRF解码包，下面会详细介绍）的<code>beam_search</code>得到<code>moves</code>（输出第几个采样点解码出了碱基，用于碱基序列和电流的对其参考），<code>qstring</code>（Q score string，以数字编码）和<code>sequence</code>（序列，以数字编码）。</p><h4 id=不开源的koi包和其开源替代>不开源的koi包和其开源替代<a hidden class=anchor aria-hidden=true href=#不开源的koi包和其开源替代>#</a></h4><p>自bonito引入CRF解码开始，bonito就将beam search的函数封装进了一个不开源的<code>ont-koi</code>包，这导致了我们无法了解具体的CRF解码实现。但万幸的是，ont在<a href=https://github.com/davidcpage/seqdist>GitHub - davidcpage/seqdist</a>和<a href=https://github.com/nanoporetech/fast-ctc-decode>GitHub - nanoporetech/fast-ctc-decode: Blitzing Fast CTC Beam Search Decoder</a>这两个repo里包含了一些CRF解码的逻辑，同时，ont还在老版bonito中负责处理duplex的部分用前述的开源代码搭出了一个可用的<code>compute_score</code>的工作流：</p><p><a href=https://github.com/nanoporetech/bonito/blob/91fb1408398fb3d8188621f1486281a2baa76318/bonito/cli/duplex.py#L217-L229>bonito/bonito/cli/duplex.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span> <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>betas</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>backward_scores</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>trans</span><span class=p>,</span> <span class=n>init</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>compute_transition_probs</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>betas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;trans&#39;</span><span class=p>:</span> <span class=n>trans</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;init&#39;</span><span class=p>:</span> <span class=n>init</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>beam_search_duplex</span><span class=p>(</span><span class=n>seq1</span><span class=p>,</span> <span class=n>path1</span><span class=p>,</span> <span class=n>t1</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>seq2</span><span class=p>,</span> <span class=n>path2</span><span class=p>,</span> <span class=n>t2</span><span class=p>,</span> <span class=n>b2</span><span class=p>,</span> <span class=n>alphabet</span><span class=o>=</span><span class=s1>&#39;NACGT&#39;</span><span class=p>,</span> <span class=n>beamsize</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>pad</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span> <span class=n>T</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>env</span> <span class=o>=</span> <span class=n>build_envelope</span><span class=p>(</span><span class=n>t1</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>seq1</span><span class=p>,</span> <span class=n>path1</span><span class=p>,</span> <span class=n>t2</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>seq2</span><span class=p>,</span> <span class=n>path2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>pad</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>crf_beam_search_duplex</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>t1</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>t2</span><span class=p>,</span> <span class=n>b2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>alphabet</span><span class=o>=</span><span class=n>alphabet</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>beam_size</span><span class=o>=</span><span class=n>beamsize</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>beam_cut_threshold</span><span class=o>=</span><span class=n>T</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>envelope</span><span class=o>=</span><span class=n>env</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>笔者同时也参考了<a href=https://github.com/marcpaga/basecalling_architectures/blob/5db4957496079d19deacb01c9f4f4957f7257f49/src/classes.py#L413-L435>Marcus对bonito crf解码的研究</a>，得到了一个利用ont的开源代码实现的compute_score函数。函数主要需要修改两处，列举如下：</p><ol><li>修改<code>backward_scores</code>函数为开源实现（可以用bonito 0.5之前的backward_score实现）：</li></ol><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L63-L68>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seqdist.sparse</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>seqdist.ctc_simple</span> <span class=kn>import</span> <span class=n>logZ_cupy</span><span class=p>,</span> <span class=n>viterbi_alignments</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>seqdist.core</span> <span class=kn>import</span> <span class=n>SequenceDist</span><span class=p>,</span> <span class=n>Max</span><span class=p>,</span> <span class=n>Log</span><span class=p>,</span> <span class=n>semiring</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>backward_scores</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>S</span><span class=p>:</span> <span class=n>semiring</span><span class=o>=</span><span class=n>Log</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>Ms</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>beta_T</span> <span class=o>=</span> <span class=n>Ms</span><span class=o>.</span><span class=n>new_full</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=o>**</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>state_len</span><span class=p>)),</span> <span class=n>S</span><span class=o>.</span><span class=n>one</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>seqdist</span><span class=o>.</span><span class=n>sparse</span><span class=o>.</span><span class=n>bwd_scores_cupy</span><span class=p>(</span><span class=n>Ms</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>idx</span><span class=p>,</span> <span class=n>beta_T</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>K</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><ol start=2><li>修改<code>compute_scores</code>函数，记得引入对应的包：</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fast_ctc_decode</span> <span class=kn>import</span> <span class=n>crf_greedy_search</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=mf>100.0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Compute scores for model.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># switch dim 1 &amp; 2</span>
</span></span><span class=line><span class=cl>        <span class=n>scores_pad</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># pad score</span>
</span></span><span class=line><span class=cl>        <span class=n>n_base</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>n_base</span>
</span></span><span class=line><span class=cl>        <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>scores_pad</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>scores_pad</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>scores_pad</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>n_base</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span><span class=o>=</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>betas</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>backward_scores</span><span class=p>(</span><span class=n>scores_pad</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>trans</span><span class=p>,</span> <span class=n>init</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>compute_transition_probs</span><span class=p>(</span><span class=n>scores_pad</span><span class=p>,</span> <span class=n>betas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>trans</span> <span class=o>=</span> <span class=n>trans</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>init</span> <span class=o>=</span> <span class=n>init</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># offload</span>
</span></span><span class=line><span class=cl>        <span class=n>tracebacks</span> <span class=o>=</span> <span class=n>trans</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>init</span> <span class=o>=</span> <span class=n>init</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>seq_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>qstring_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>moves_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>tracebacks_batch</span> <span class=o>=</span> <span class=n>tracebacks</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>  <span class=c1># (T, 256, 5)</span>
</span></span><span class=line><span class=cl>            <span class=n>init_batch</span> <span class=o>=</span> <span class=n>init</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>  <span class=c1># (256,)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># greedy decode, cef_beam_search dont output qstring</span>
</span></span><span class=line><span class=cl>            <span class=n>seq_batch</span><span class=p>,</span> <span class=n>path_batch</span> <span class=o>=</span> <span class=n>crf_greedy_search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>network_output</span><span class=o>=</span><span class=n>tracebacks_batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>init_state</span><span class=o>=</span><span class=n>init_batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>alphabet</span><span class=o>=</span><span class=s2>&#34;NACGT&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qstring</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qscale</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qbias</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># re-encode</span>
</span></span><span class=line><span class=cl>            <span class=n>seq_batch_str</span> <span class=o>=</span> <span class=n>seq_batch</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>seq_batch</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_batch_str</span> <span class=o>=</span> <span class=n>seq_batch</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>seq_batch</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>seq_as_numbers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>frombuffer</span><span class=p>(</span><span class=n>seq_batch_str</span><span class=o>.</span><span class=n>encode</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_as_numbers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>frombuffer</span><span class=p>(</span><span class=n>qstring_batch_str</span><span class=o>.</span><span class=n>encode</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>seq_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>seq_as_numbers</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>path_batch</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>qstring_as_numbers</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>path_batch</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>            <span class=n>moves_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;qstring&#39;</span><span class=p>:</span> <span class=n>qstring_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;sequence&#39;</span><span class=p>:</span> <span class=n>seq_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;moves&#39;</span><span class=p>:</span> <span class=n>moves_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></div><div class="callout callout-warning">需要注意的是，此处的开源实现将<code>beam_search</code>换成了<code>crf_greedy_search</code>，<strong>因此basecaller的准确率可能略有下降</strong>，但根据笔者的测试，准确率仅下降约0.3%，笔者认为不完美，但可接受。</div><p><em>此时，得到的<code>qstring</code>，<code>sequence</code>是一个长<code>current_length</code>的矩阵。其中部份index为0（说明这个位置并没有解码出新的碱基），剩下的index则是数字（数字编码的ATCG碱基，或q string分数）。</em></p><h3 id=拼接basecaller结果和输出字符>拼接basecaller结果和输出字符<a hidden class=anchor aria-hidden=true href=#拼接basecaller结果和输出字符>#</a></h3><p>由于神经网络的窗口大小有限，在遇到长序列的电流时，电流会按照网络配置中给定的<code>chunksize</code>和<code>overlap</code>拆成一段段的短序列。因此，在完成解码后，得到的<code>qstring</code>，<code>sequence</code>和<code>moves</code>需要经过<a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/basecall.py#L13-L14>stitch_results</a>函数重新根据read_id拼接在一起。</p><p>在拼接完后，序列则会经过如<a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L105-L106>path_to_str</a>这样的解码函数被解码回碱基序列/Q Score。最后，经过格式化就可以输出为fastq，或过一次<a href=https://github.com/lh3/minimap2/blob/master/python/mappy.pyx>mappy</a>之后即可输出aligned sam/bam文件了。</p><hr><h2 id=训练bonito>训练Bonito<a hidden class=anchor aria-hidden=true href=#训练bonito>#</a></h2><h3 id=数据集结构>数据集结构<a hidden class=anchor aria-hidden=true href=#数据集结构>#</a></h3><p>参考bonito 0.8.1的官方文档，我们至少需要三个<code>.npy</code>文件才能构成一个训练basecaller的数据集（假设训练时用的每段电流长度为<code>chunksize</code>）。参考bonito的<a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/cli/download.py#L130-L131>download.py</a>，目前bonito提供了三个训练数据集，列举如下：</p><table><thead><tr><th>Url</th><th>flowcell</th></tr></thead><tbody><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip</a></td><td>dna_r9.4.1</td></tr><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip</a></td><td>dna_r10.4.1</td></tr><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip</a></td><td>rna004</td></tr></tbody></table><p>每个数据集下载下来并解压都包含三个<code>.npy</code>文件：</p><table><thead><tr><th>Filename</th><th>Shape</th><th>用途</th></tr></thead><tbody><tr><td>references.npy</td><td>(data_length, max_len_of_reference) <code>uint8</code></td><td>存储每个信号chunk对应的序列，用诸如<code>{'A': 1, 'C': 2, 'G': 3, 'T': 4}</code>的规则编码ATCG，余下位置用0填充</td></tr><tr><td>reference_lengths.npy</td><td>(data_length,) <code>uint8</code></td><td>存储每个信号chunk对应的序列的<strong>长度</strong>（不pad0的部分）</td></tr><tr><td>chunks.npy</td><td>(data_length, chunksize) <code>float32</code></td><td>存储每个信号chunk的电流讯号</td></tr></tbody></table><p>可选的，数据集文件夹中也可以包含一个名为<code>validation_sets</code>的文件夹，如果存在此文件夹，里面的<code>references.npy</code>，<code>reference_lengths.npy</code>，<code>chunks.npy</code>将作为验证集使用。</p><h3 id=训练相关的命令>训练相关的命令<a hidden class=anchor aria-hidden=true href=#训练相关的命令>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># bonito train</span>
</span></span><span class=line><span class=cl>positional arguments:
</span></span><span class=line><span class=cl>  training_directory
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>optional arguments:
</span></span><span class=line><span class=cl>  -h, --help            show this <span class=nb>help</span> message and <span class=nb>exit</span>
</span></span><span class=line><span class=cl>  --config CONFIG
</span></span><span class=line><span class=cl>  --pretrained PRETRAINED
</span></span><span class=line><span class=cl>  --directory DIRECTORY
</span></span><span class=line><span class=cl>  --device DEVICE
</span></span><span class=line><span class=cl>  --lr LR
</span></span><span class=line><span class=cl>  --seed SEED
</span></span><span class=line><span class=cl>  --epochs EPOCHS
</span></span><span class=line><span class=cl>  --batch BATCH
</span></span><span class=line><span class=cl>  --chunks CHUNKS
</span></span><span class=line><span class=cl>  --valid-chunks VALID_CHUNKS
</span></span><span class=line><span class=cl>  --no-amp
</span></span><span class=line><span class=cl>  -f, --force
</span></span><span class=line><span class=cl>  --restore-optim
</span></span><span class=line><span class=cl>  --nondeterministic
</span></span><span class=line><span class=cl>  --save-optim-every SAVE_OPTIM_EVERY
</span></span><span class=line><span class=cl>  --grad-accum-split GRAD_ACCUM_SPLIT
</span></span><span class=line><span class=cl>  --quantile-grad-clip
</span></span><span class=line><span class=cl>  --num-workers NUM_WORKERS
</span></span></code></pre></div><h3 id=训练时的loss函数计算>训练时的loss函数计算<a hidden class=anchor aria-hidden=true href=#训练时的loss函数计算>#</a></h3><p>和推理时使用的CRF不同，bonito在训练时，使用的解码器和loss函数并不是先前提到的<code>compute_score</code>函数。</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L196-L199>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>posteriors</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span> <span class=o>+</span> <span class=mf>1e-8</span>
</span></span><span class=line><span class=cl>        <span class=n>tracebacks</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>viterbi</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>log</span><span class=p>())</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>int16</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>path_to_str</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>tracebacks</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()]</span>
</span></span></code></pre></div><p>而是用seqdist的viterbi search直接得出了序列，然后跟标准参考序列比较得出了一个准确率。</p><h3 id=训练命令>训练命令<a hidden class=anchor aria-hidden=true href=#训练命令>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bonito train <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--config config.toml <span class=se>\ </span><span class=c1># 前面提到的模型config，chunksize等会从数据集里自动读取</span>
</span></span><span class=line><span class=cl>--device cuda:0 <span class=se>\ </span><span class=c1># 显卡</span>
</span></span><span class=line><span class=cl>--epochs <span class=m>5</span> <span class=c1># epoch</span>
</span></span><span class=line><span class=cl>--lr 5e-4 <span class=se>\ </span><span class=c1># 学习率</span>
</span></span><span class=line><span class=cl>--batch <span class=m>96</span> <span class=se>\ </span><span class=c1># batchsize</span>
</span></span><span class=line><span class=cl>--pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0 <span class=se>\ </span><span class=c1># 现有模型，可以从ont提供的模型选，或者传入其他模型所在的目录</span>
</span></span><span class=line><span class=cl>--directory dataset_dir/  <span class=se>\ </span><span class=c1># chunks.npy等所在的文件夹</span>
</span></span><span class=line><span class=cl>model_dir/
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.sparktour.me/tags/bonito/>Bonito</a></li></ul><nav class=paginav><a class=prev href=https://blog.sparktour.me/posts/2024/10/03/2024-summer-usa-travel-notes/><span class=title>« 上一页</span><br><span>美国旅行游记</span>
</a><a class=next href=https://blog.sparktour.me/posts/2024/08/01/2024-korea-trip/><span class=title>下一页 »</span><br><span>韩国之旅：一座典型的东北亚大都会</span></a></nav></footer><div class="callout callout-default"><img src=https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.svg alt="CC BY-NC-SA 4.0" style=width:88px;height:31px><p style=font-size:12px>Licensed Under <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener>CC BY-NC-SA 4.0</a></p><p style=font-size:12px>Post Link: <a href=https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/ target=_blank rel=noopener>https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/</a></p></div><script src=https://s4.zstatic.net/ajax/libs/disqusjs/3.0.2/disqusjs.es2015.umd.min.js crossorigin=anonymous></script><div id=disqusjs></div><script>const disqusjs=new DisqusJS({shortname:"sparktour",siteName:"",identifier:"",url:"",title:"",api:"https://disqus.com/api/",apikey:"QhJnXpS5igyHkjYQ91XYC4dSAuEJYAEsHX8hjLrRc1HU9AApOHLrqkwwIp2sKOLk",admin:"",adminLabel:""});disqusjs.render(document.getElementById("disqusjs"))</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.sparktour.me/>Sparktour's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>