<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Look at the Nanopore Basecaller: Bonito | Sparktour’s Blog</title><meta name=keywords content="bonito"><meta name=description content="Bonito, named after the bonito fish, is a basecaller developed by Oxford Nanopore Technology. In this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the secondary development of Bonito (or even other nanopore sequencing basecallers)."><meta name=author content="sparktour"><link rel=canonical href=https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><link crossorigin=anonymous href=/assets/css/stylesheet.93f625d739f1d6a5c6f20c146bc6a8d26b233492b34b2220c54b12fd46a04ded.css integrity="sha256-k/Yl1znx1qXG8gwUa8ao0msjNJKzSyIgxUsS/UagTe0=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.sparktour.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.sparktour.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.sparktour.me/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.sparktour.me/apple-touch-icon.png><link rel=mask-icon href=https://blog.sparktour.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><link rel=alternate hreflang=en href=https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://blog.sparktour.me/scss/callout.css><link rel=stylesheet href=https://s4.zstatic.net/ajax/libs/disqusjs/3.0.2/styles/disqusjs.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-6EJ4YX1XZ8"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6EJ4YX1XZ8")}</script><meta property="og:url" content="https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"><meta property="og:site_name" content="Sparktour’s Blog"><meta property="og:title" content="A Look at the Nanopore Basecaller: Bonito"><meta property="og:description" content="Bonito, named after the bonito fish, is a basecaller developed by Oxford Nanopore Technology. In this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the secondary development of Bonito (or even other nanopore sequencing basecallers)."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-25T21:00:00+00:00"><meta property="article:modified_time" content="2025-01-11T17:33:54+08:00"><meta property="article:tag" content="Bonito"><meta property="og:image" content="https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg"><meta name=twitter:title content="A Look at the Nanopore Basecaller: Bonito"><meta name=twitter:description content="Bonito, named after the bonito fish, is a basecaller developed by Oxford Nanopore Technology. In this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the secondary development of Bonito (or even other nanopore sequencing basecallers)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.sparktour.me/en/posts/"},{"@type":"ListItem","position":2,"name":"A Look at the Nanopore Basecaller: Bonito","item":"https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Look at the Nanopore Basecaller: Bonito","name":"A Look at the Nanopore Basecaller: Bonito","description":"Bonito, named after the bonito fish, is a basecaller developed by Oxford Nanopore Technology. In this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the secondary development of Bonito (or even other nanopore sequencing basecallers).","keywords":["bonito"],"articleBody":" This article will be continuously updated as my research progresses. The currently planned additions include:\nTraining dataset format and some techniques Explanation of the principles of CRF Overview of Bonito Basecaller Bonito, named after the bonito fish, is a basecaller framework developed by Oxford Nanopore Technology. The trained basecaller weights can be exported to dorado, guppy, etc. Due to the scarcity of qualitative descriptions of basecallers on the internet, I have spent a lot of time and effort studying the architecture and data flow of these basecallers. Therefore, in this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the development of Bonito (or even other nanopore sequencing basecallers). I hope to provide some inspiration for those who come after.\nWhat is a Basecaller? To make it simple, a “basecaller” is a neural network. Its input is the current signal obtained from nanopore translocation, and its output is the ATCG bases and some other debugging information (in fasta, fastq or bam format). In ONT’s devices, the current is generally stored in fast5 format (based on hdf5) and the recently released pod5 format. Regardless of the format, the stored data structure includes at least the following information:\nStored Item Description read_id uuid, used to uniquely identify the sequence raw current Sampled values directly output from the amplifier, without units scale, offset Amplification and offset coefficients, the current in pA can be obtained by pA_val = scale * (raw + offset) metadata Some information related to sequencing, such as time, the kit used, the sequencing flowcell, etc. Some readers may notice that the current signal from nanopore sequencing is somewhat similar to the audio signal in speech recognition. For example, the sound recorded by a microphone is also stored as a one-dimensional array. At the same time, the ATCG output by the basecaller is also similar to the transcript obtained by the speech recognition network (ASR). Therefore, we can also consider the basecaller in nanopore sequencing as a special ASR network.\nArchitecture of Bonito The code referenced in this section has listed the specific github repo and commit. Readers can refer to the source code for reading. The following is the model architecture diagram output by torchinfo (dna_r9.4.1_e8_hac@v3.3, state_len=4), the input of the model is [64,5000] (batchsize, current_length)\n========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== Model [64, 1000, 1024] -- ├─Sequential: 1-1 [64, 1000, 1024] -- │ └─Convolution: 2-1 [64, 4, 5000] -- │ │ └─Conv1d: 3-1 [64, 4, 5000] 24 │ │ └─Swish: 3-2 [64, 4, 5000] -- │ └─Convolution: 2-2 [64, 16, 5000] -- │ │ └─Conv1d: 3-3 [64, 16, 5000] 336 │ │ └─Swish: 3-4 [64, 16, 5000] -- │ └─Convolution: 2-3 [64, 384, 1000] -- │ │ └─Conv1d: 3-5 [64, 384, 1000] 117,120 │ │ └─Swish: 3-6 [64, 384, 1000] -- │ └─Permute: 2-4 [1000, 64, 384] -- │ └─LSTM: 2-5 [1000, 64, 384] -- │ │ └─LSTM: 3-7 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-6 [1000, 64, 384] -- │ │ └─LSTM: 3-8 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-7 [1000, 64, 384] -- │ │ └─LSTM: 3-9 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-8 [1000, 64, 384] -- │ │ └─LSTM: 3-10 [1000, 64, 384] 1,182,720 │ └─LSTM: 2-9 [1000, 64, 384] -- │ │ └─LSTM: 3-11 [1000, 64, 384] 1,182,720 │ └─Permute: 2-10 [64, 1000, 384] -- │ └─LinearCRFEncoder: 2-11 [64, 1000, 1024] -- │ │ └─Linear: 3-12 [64, 1000, 1024] 394,240 │ │ └─Tanh: 3-13 [64, 1000, 1024] -- ========================================================================================== Total params: 6,425,320 Trainable params: 6,417,640 Non-trainable params: 7,680 Total mult-adds (G): 386.11 ========================================================================================== Input size (MB): 0.64 Forward/backward pass size (MB): 877.57 Params size (MB): 12.85 Estimated Total Size (MB): 891.06 ========================================================================================== Fig. 1 As shown in Figure 1 of Marcus et al.’s article, the model structure of Bonito (and some common basecallers) is mainly divided into three parts: CNN, LSTM/RNN, etc. Encoder, and CTC/CRF, etc. Decoder.\nbonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef rnn_encoder(n_base, state_len, insize=1, first_conv_size=4, stride=5, winlen=19, activation='swish', rnn_type='lstm', features=768, scale=5.0, blank_score=None, expand_blanks=True, num_layers=5, norm=None): rnn = layers[rnn_type] return Serial([ conv(insize, first_conv_size, ks=5, bias=True, activation=activation, norm=norm), conv(first_conv_size, 16, ks=5, bias=True, activation=activation, norm=norm), conv(16, features, ks=winlen, stride=stride, bias=True, activation=activation, norm=norm), Permute([2, 0, 1]), *(rnn(features, features, reverse=(num_layers - i) % 2) for i in range(num_layers)), LinearCRFEncoder( features, n_base, state_len, activation='tanh', scale=scale, blank_score=blank_score, expand_blanks=expand_blanks ) ]) Configuration File (a.k.a config.toml) Take dna_r9.4.1_e8_hac@v3.3 (based on bonito/bonito/models/configs/dna_r9.4.1@v3.1.toml at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub ) as an example:\n[global_norm] # State Length of CRF, determine how many state CRF decoder need to consider state_len = 4 [input] features = 1 [labels] labels = [ \"N\", \"A\", \"C\", \"G\", \"T\",] # labels of bases, N means empty state. [qscore] scale = 0.9356 bias = -0.1721 # bias factor of Q Score [model] package = \"bonito.crf\" # use CRF or CTC at decoder (since bonito v0.4, only CRF is valid) [encoder] scale = 5.0 rnn_type = \"lstm\" winlen = 19 features = 384 activation = \"swish\" stride = 5 # downsample stride blank_score = 2.0 [basecaller] # config when basecalling, don't affect training batchsize = 512 chunksize = 10000 overlap = 500 CNN After the one-dimensional array of current is input, it will first go through three convolutions for feature extraction. The implementation code of the convolution is located here, it can be seen that it is a standard pytorch convolution implementation (Conv1d — PyTorch 2.4 documentation), there is nothing too special. But it should be noted that in order to speed up the calculation, Bonito sets the stride to 5 in the third convolutional layer, which downsamples the signal by 5 times (5000 -\u003e 1000). Finally, the output of the convolutional layer is [64, 384, 1000] (batch, channel, signal_length).\nbonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\n@register class Convolution(Module): def __init__(self, insize, size, winlen, stride=1, padding=0, bias=True, activation=None, norm=None): super().__init__() self.conv = torch.nn.Conv1d(insize, size, winlen, stride=stride, padding=padding, bias=bias) self.activation = layers.get(activation, lambda: activation)() if isinstance(norm, dict): self.norm = from_dict(norm) elif isinstance(norm, str): self.norm = layers[norm](size) else: self.norm = norm def forward(self, x): h = self.conv(x) if self.norm is not None: h = self.norm(h) if self.activation is not None: h = self.activation(h) return h def to_dict(self, include_weights=False): res = { \"insize\": self.conv.in_channels, \"size\": self.conv.out_channels, \"bias\": self.conv.bias is not None, \"winlen\": self.conv.kernel_size[0], \"stride\": self.conv.stride[0], \"padding\": self.conv.padding[0], } if self.activation is not None: res[\"activation\"] = self.activation.name if self.norm is not None: res[\"norm\"] = to_dict(self.norm, include_weights) #simplify default case e.g. norm=\"batchnorm\" if not include_weights and self.norm.name in layers: if res[\"norm\"] == to_dict(layers[self.norm.name](res[\"size\"])): res[\"norm\"] = self.norm.name if include_weights: res['params'] = { 'W': self.conv.weight, 'b': self.conv.bias if self.conv.bias is not None else [] } return res LSTM After feature extraction, the signal passes through a fully connected layer, and then enters the LSTM layer to learn the temporal relationship of signal features. The LSTM here is also based on the standard LSTM — PyTorch 2.4 documentation:\nbonito/bonito/nn.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub\n@register class LSTM(RNNWrapper): def __init__(self, size, insize, bias=True, reverse=False): super().__init__(torch.nn.LSTM, size, insize, bias=bias, reverse=reverse) def to_dict(self, include_weights=False): res = { 'size': self.rnn.hidden_size, 'insize': self.rnn.input_size, 'bias': self.rnn.bias, 'reverse': self.reverse, } if include_weights: res['params'] = { 'iW': self.rnn.weight_ih_l0.reshape(4, self.rnn.hidden_size, self.rnn.input_size), 'sW': self.rnn.weight_hh_l0.reshape(4, self.rnn.hidden_size, self.rnn.hidden_size), 'b': self.rnn.bias_ih_l0.reshape(4, self.rnn.hidden_size) } return res The shape of the LSTM output layer is [1000, 64, 384] (signal_length, batch, channel)\nCRF Encoder After the data leaves the LSTM, it will enter a fully connected layer to output a matrix for CRF decoding. From the code, we can see that this encoder only performs a non-linear transformation on the data, and rearranges the output.\nbonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\n@register class LinearCRFEncoder(Module): def __init__(self, insize, n_base, state_len, bias=True, scale=None, activation=None, blank_score=None, expand_blanks=True, permute=None): super().__init__() self.scale = scale self.n_base = n_base self.state_len = state_len self.blank_score = blank_score self.expand_blanks = expand_blanks size = (n_base + 1) * n_base**state_len if blank_score is None else n_base**(state_len + 1) self.linear = torch.nn.Linear(insize, size, bias=bias) self.activation = layers.get(activation, lambda: activation)() self.permute = permute def forward(self, x): if self.permute is not None: x = x.permute(*self.permute) scores = self.linear(x) if self.activation is not None: scores = self.activation(scores) if self.scale is not None: scores = scores * self.scale if self.blank_score is not None and self.expand_blanks: T, N, C = scores.shape scores = torch.nn.functional.pad( scores.view(T, N, C // self.n_base, self.n_base), (1, 0, 0, 0, 0, 0, 0, 0), value=self.blank_score ).view(T, N, -1) return scores The part with weights in the entire neural network ends here. The following CRF decoder does not include any weights. (Therefore, during training and inference, Bonito uses different decoders, which will be explained in detail later)\nCRF Decoder The core of the CRF Decoder is in this function:\nbonito/bonito/crf/basecall.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef compute_scores(model, batch, beam_width=32, beam_cut=100.0, scale=1.0, offset=0.0, blank_score=2.0, reverse=False): \"\"\" Compute scores for model. \"\"\" with torch.inference_mode(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) with torch.cuda.device(scores.device): sequence, qstring, moves = beam_search( scores, beam_width=beam_width, beam_cut=beam_cut, scale=scale, offset=offset, blank_score=blank_score ) return { 'moves': moves, 'qstring': qstring, 'sequence': sequence, } In compute_scores, scores is the matrix inferred by the aforementioned neural network, with a size of [64, 1000, 1024] (batch, current_length, state), $1024=4^5(4base^{4state+1})$. Then, if RNA is being sequenced, the score is reversed (this is also why the reference fasta needs to be reversed when training RNA). Finally, call koi (a non-open source CRF decoding package developed by ONT, which will be explained in detail below) beam_search to get moves (output which sampling point decoded a base, used for base sequence and current alignment reference), qstring (Q score string, encoded in numbers) and sequence (sequence, encoded in numbers).\nClose-sourced koi Package and Its Open Source Alternatives Since Bonito introduced CRF decoding, Bonito has encapsulated the beam search function into a close-sourced ont-koi package, which makes it impossible for us to understand the specific implementation of CRF decoding. But fortunately, ONT has included some CRF decoding logic in these two repos: GitHub - davidcpage/seqdist and GitHub - nanoporetech/fast-ctc-decode: Blitzing Fast CTC Beam Search Decoder. At the same time, ONT used the aforementioned open-source code in the old version of Bonito to build a usable compute_score workflow to handle the duplex part:\nbonito/bonito/cli/duplex.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub\ndef compute_scores(model, batch, reverse=False): with torch.no_grad(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model.encoder(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) betas = model.seqdist.backward_scores(scores.to(torch.float32)) trans, init = model.seqdist.compute_transition_probs(scores, betas) return { 'trans': trans.to(dtype).transpose(0, 1), 'init': init.to(dtype).unsqueeze(1), } def beam_search_duplex(seq1, path1, t1, b1, seq2, path2, t2, b2, alphabet='NACGT', beamsize=5, pad=40, T=0.01): env = build_envelope(t1.shape[0], seq1, path1, t2.shape[0], seq2, path2, padding=pad) return crf_beam_search_duplex( t1, b1, t2, b2, alphabet=alphabet, beam_size=beamsize, beam_cut_threshold=T, envelope=env, ) I have also referred to Marcus’s research on Bonito CRF decoding, and obtained a compute_score function implemented using ONT’s open source code. The function mainly needs to be modified in two places, as listed below:\nModify the backward_scores function to an open source implementation (the backward_score implementation before Bonito 0.5 can be used): bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\nimport seqdist.sparse from seqdist.ctc_simple import logZ_cupy, viterbi_alignments from seqdist.core import SequenceDist, Max, Log, semiring def backward_scores(self, scores, S: semiring=Log): T, N, _ = scores.shape Ms = scores.reshape(T, N, -1, self.n_base + 1) beta_T = Ms.new_full((N, self.n_base**(self.state_len)), S.one) return seqdist.sparse.bwd_scores_cupy(Ms, self.idx, beta_T, S, K=1) Modify the compute_scores function, remember to import the corresponding packages: from fast_ctc_decode import crf_greedy_search def compute_scores(model, batch, beam_width=32, beam_cut=100.0, scale=1.0, offset=0.0, blank_score=2.0, reverse=False): \"\"\" Compute scores for model. \"\"\" with torch.inference_mode(): device = next(model.parameters()).device dtype = torch.float16 if half_supported() else torch.float32 scores = model(batch.to(dtype).to(device)) if reverse: scores = model.seqdist.reverse_complement(scores) # switch dim 1 \u0026 2 scores_pad = scores.permute(1, 0, 2) # pad score n_base = model.seqdist.n_base T, N, C = scores_pad.shape scores_pad = torch.nn.functional.pad( scores_pad.view(T, N, C // n_base, n_base), (1, 0, 0, 0, 0, 0, 0, 0), value=blank_score ).view(T, N, -1) betas = model.seqdist.backward_scores(scores_pad.to(torch.float32)) trans, init = model.seqdist.compute_transition_probs(scores_pad, betas) trans = trans.to(torch.float32).transpose(0, 1) init = init.to(torch.float32).unsqueeze(1) # offload tracebacks = trans.cpu() init = init.cpu() seq_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') qstring_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') moves_tensor = torch.zeros((N, T), dtype=torch.uint8, device='cpu') for batch_idx in range(N): tracebacks_batch = tracebacks[batch_idx].numpy() # (T, 256, 5) init_batch = init[batch_idx][0].numpy() # (256,) # greedy decode, cef_beam_search dont output qstring seq_batch, path_batch = crf_greedy_search( network_output=tracebacks_batch, init_state=init_batch, alphabet=\"NACGT\", qstring=True, qscale=1, qbias=1 ) # re-encode seq_batch_str = seq_batch[:len(seq_batch) // 2] qstring_batch_str = seq_batch[len(seq_batch) // 2:] seq_as_numbers = np.frombuffer(seq_batch_str.encode(), dtype=np.uint8).copy() qstring_as_numbers = np.frombuffer(qstring_batch_str.encode(), dtype=np.uint8).copy() seq_tensor[batch_idx, path_batch] = torch.from_numpy(seq_as_numbers[:len(path_batch)]) qstring_tensor[batch_idx, path_batch] = torch.from_numpy(qstring_as_numbers[:len(path_batch)]) moves_tensor[batch_idx, path_batch] = 1 return { 'qstring': qstring_tensor, 'sequence': seq_tensor, 'moves': moves_tensor, } It should be noted that the open-source implementation here has replaced beam_search with crf_greedy_search. Therefore, the accuracy of the basecaller may be slightly reduced. However, according to my tests, the accuracy only decreases by about 0.3%, which I think is not perfect but acceptable. At this point, the obtained qstring, sequence is a matrix with a length of current_length. Some indices are 0 (indicating that no new bases were decoded at this position), and the remaining indices are numbers (number-encoded ATCG bases or q string scores).\nStitching Basecaller Results and Outputting Characters Due to the limited window size of the neural network, when encountering long sequences of current, the current will be split into short sequences according to the chunksize and overlap given in the network configuration. Therefore, after completing the decoding, the obtained qstring, sequence and moves need to be re-stitched together according to read_id by the stitch_results function.\nAfter stitching, the sequence will be decoded back to the base sequence/Q Score through decoding functions such as path_to_str. Finally, after formatting, it can be output as fastq, or after going through mappy once, it can be output as an aligned sam/bam file.\nTraining Bonito Dataset Structure Referencing the official documentation of Bonito 0.8.1, we need at least three .npy files to construct a training basecaller dataset (assuming that the length of each current segment used during training is chunksize). Referencing Bonito’s download.py, Bonito currently provides three training datasets, listed below:\nUrl flowcell https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip dna_r9.4.1 https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip dna_r10.4.1 https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip rna004 Each downloaded and decompressed dataset contains three .npy files:\nFilename Shape Purpose references.npy (data_length, max_len_of_reference) uint8 Stores the sequence corresponding to each signal chunk, encoded using rules such as {'A': 1, 'C': 2, 'G': 3, 'T': 4} for ATCG, with the remaining positions padded with 0 reference_lengths.npy (data_length,) uint8 Stores the length of the sequence corresponding to each signal chunk (the part not padded with 0) chunks.npy (data_length, chunksize) float32 Stores the current signal of each signal chunk Optionally, the dataset folder can also contain a folder named validation_sets. If this folder exists, the references.npy, reference_lengths.npy, and chunks.npy inside it will be used as the validation set.\nTraining-related Commands # bonito train positional arguments: training_directory optional arguments: -h, --help show this help message and exit --config CONFIG --pretrained PRETRAINED --directory DIRECTORY --device DEVICE --lr LR --seed SEED --epochs EPOCHS --batch BATCH --chunks CHUNKS --valid-chunks VALID_CHUNKS --no-amp -f, --force --restore-optim --nondeterministic --save-optim-every SAVE_OPTIM_EVERY --grad-accum-split GRAD_ACCUM_SPLIT --quantile-grad-clip --num-workers NUM_WORKERS Loss Function Calculation During Training Unlike the CRF used during inference, Bonito does not use the previously mentioned compute_score function as the decoder and loss function during training.\nbonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub\ndef decode_batch(self, x): scores = self.seqdist.posteriors(x.to(torch.float32)) + 1e-8 tracebacks = self.seqdist.viterbi(scores.log()).to(torch.int16).T return [self.seqdist.path_to_str(x) for x in tracebacks.cpu().numpy()] Instead, it uses seqdist’s viterbi search to directly obtain the sequence, and then compares it with the standard reference sequence to obtain an accuracy.\nTraining Command bonito train \\ --config config.toml \\ # The model config mentioned earlier, chunksize, etc., will be automatically read from the dataset --device cuda:0 \\ # GPU --epochs 5 # epoch --lr 5e-4 \\ # learning rate --batch 96 \\ # batchsize --pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0 \\ # Existing model, you can select from the models provided by ONT, or pass in the directory where other models are located --directory dataset_dir/ \\ # Folder containing chunks.npy, etc. model_dir/ This command initiates the training process. Let’s break down the key components:\nbonito train: This is the main command to start the training of a Bonito model. --config config.toml: This specifies the configuration file for the model. This file defines various parameters like the network architecture, number of states for CRF, input/label configurations, learning rate, and more. The config.toml file was described in detail earlier. --device cuda:0: This argument tells Bonito to use the first CUDA-enabled GPU (if available). If you have multiple GPUs, you can specify a different ID (e.g., cuda:1). If you want to train on CPU, you can use cpu as an argument, but training on GPU will be significantly faster. --epochs 5: This sets the number of training epochs, indicating how many times the entire training dataset will be passed through the model. --lr 5e-4: This sets the learning rate for the optimizer. A lower learning rate can result in finer tuning of the weights but may also require more training epochs. --batch 96: This specifies the batch size, i.e., the number of training examples that the model will process in each iteration. Larger batch sizes can utilize GPU resources more efficiently, but may also lead to memory issues, particularly with smaller GPUs. --pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0: This crucial parameter specifies the model that will be used as a starting point. This leverages transfer learning, enabling you to train more quickly and effectively. You can use ONT’s pre-trained models, like the example provided (dna_r10.4.1_e8.2_400bps_hac@v5.0.0) or point to a custom pre-trained model. --directory dataset_dir/: This points to the directory containing the training dataset. Bonito expects the training data to be in the format explained in the “Dataset Structure” section. It will automatically load the chunks.npy, references.npy, and reference_lengths.npy from the provided directory, and potentially validation data from the validation_sets subfolder. model_dir/: Finally, model_dir/ is the directory where the trained model (including model weights) and training checkpoints will be saved. ","wordCount":"2968","inLanguage":"en","image":"https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg","datePublished":"2024-09-25T21:00:00Z","dateModified":"2025-01-11T17:33:54+08:00","author":{"@type":"Person","name":"sparktour"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/"},"publisher":{"@type":"Organization","name":"Sparktour’s Blog","logo":{"@type":"ImageObject","url":"https://blog.sparktour.me/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.sparktour.me/en/ accesskey=h title="Sparktour’s Blog (Alt + H)">Sparktour’s Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://blog.sparktour.me/ title=中文 aria-label=中文>中文</a></li></ul></div></div><ul id=menu><li><a href=https://blog.sparktour.me/en/archives title=Archive><span>Archive</span></a></li><li><a href=https://blog.sparktour.me/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.sparktour.me/en/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://blog.sparktour.me/en/about/ title=About><span>About</span></a></li><li><a href=https://blog.sparktour.me/en/friends/ title=Friends><span>Friends</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.sparktour.me/en/>Home</a>&nbsp;»&nbsp;<a href=https://blog.sparktour.me/en/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">A Look at the Nanopore Basecaller: Bonito</h1><div class=post-description>Bonito, named after the bonito fish, is a basecaller developed by Oxford Nanopore Technology. In this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the secondary development of Bonito (or even other nanopore sequencing basecallers).</div><div class=post-meta><span title='2024-09-25 21:00:00 +0000 UTC'>2024-09-25</span>&nbsp;·&nbsp;<span title='2025-01-11 17:33:54 +0800 +0800'>LastMod: 2025-01-11</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;sparktour&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://blog.sparktour.me/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/>中文</a></li></ul></div></header><figure class=entry-cover><img loading=eager src=https://assets.sparktour.me/img/blog/2024/a-look-at-nanopore-basecaller-bonito/Sarda_sarda.jpg alt="Bonito Fish"><figcaption>Bonito Fish</figcaption></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#overview-of-bonito-basecaller aria-label="Overview of Bonito Basecaller">Overview of Bonito Basecaller</a><ul><li><a href=#what-is-a-basecaller aria-label="What is a Basecaller?">What is a Basecaller?</a></li><li><a href=#architecture-of-bonito aria-label="Architecture of Bonito">Architecture of Bonito</a><ul><li><a href=#configuration-file-aka-configtoml aria-label="Configuration File (a.k.a config.toml)">Configuration File (a.k.a config.toml)</a></li><li><a href=#cnn aria-label=CNN>CNN</a></li><li><a href=#lstm aria-label=LSTM>LSTM</a></li><li><a href=#crf-encoder aria-label="CRF Encoder">CRF Encoder</a></li><li><a href=#crf-decoder aria-label="CRF Decoder">CRF Decoder</a><ul><li><a href=#close-sourced-koi-package-and-its-open-source-alternatives aria-label="Close-sourced koi Package and Its Open Source Alternatives">Close-sourced koi Package and Its Open Source Alternatives</a></li></ul></li><li><a href=#stitching-basecaller-results-and-outputting-characters aria-label="Stitching Basecaller Results and Outputting Characters">Stitching Basecaller Results and Outputting Characters</a></li></ul></li><li><a href=#training-bonito aria-label="Training Bonito">Training Bonito</a><ul><li><a href=#dataset-structure aria-label="Dataset Structure">Dataset Structure</a></li><li><a href=#training-related-commands aria-label="Training-related Commands">Training-related Commands</a></li><li><a href=#loss-function-calculation-during-training aria-label="Loss Function Calculation During Training">Loss Function Calculation During Training</a></li><li><a href=#training-command aria-label="Training Command">Training Command</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><div class="callout callout-info"><p>This article will be continuously updated as my research progresses. The currently planned additions include:</p><ul><li>Training dataset format and some techniques</li><li>Explanation of the principles of CRF</li></ul></div><h1 id=overview-of-bonito-basecaller>Overview of Bonito Basecaller<a hidden class=anchor aria-hidden=true href=#overview-of-bonito-basecaller>#</a></h1><p><a href=https://github.com/nanoporetech/bonito>Bonito</a>, named after the bonito fish, is a <a href=https://nanoporetech.com/platform/technology/basecalling>basecaller</a> framework developed by <a href=https://nanoporetech.com/>Oxford Nanopore Technology</a>. The trained basecaller weights can be exported to <a href=https://github.com/nanoporetech/dorado>dorado</a>, <a href=https://nanoporetech.com/document/Guppy-protocol>guppy</a>, etc. Due to the scarcity of qualitative descriptions of basecallers on the internet, I have spent a lot of time and effort studying the architecture and data flow of these basecallers. Therefore, in this article, I will try to explain, in an easy-to-understand way, the data flow and data formats of Bonito, as well as some knowledge needed for the development of Bonito (or even other nanopore sequencing basecallers). I hope to provide some inspiration for those who come after.</p><h2 id=what-is-a-basecaller>What is a Basecaller?<a hidden class=anchor aria-hidden=true href=#what-is-a-basecaller>#</a></h2><p>To make it simple, a &ldquo;basecaller&rdquo; is a neural network. Its input is the current signal obtained from nanopore translocation, and its output is the ATCG bases and some other debugging information (in fasta, fastq or bam format). In ONT&rsquo;s devices, the current is generally stored in <a href=https://medium.com/@shiansu/a-look-at-the-nanopore-fast5-format-f711999e2ff6>fast5</a> format (based on hdf5) and the recently released <a href=https://pod5-file-format.readthedocs.io/en/>pod5</a> format. Regardless of the format, the stored data structure includes at least the following information:</p><table><thead><tr><th>Stored Item</th><th>Description</th></tr></thead><tbody><tr><td>read_id</td><td>uuid, used to uniquely identify the sequence</td></tr><tr><td>raw current</td><td>Sampled values directly output from the amplifier, without units</td></tr><tr><td>scale, offset</td><td>Amplification and offset coefficients, the current in pA can be obtained by <code>pA_val = scale * (raw + offset)</code></td></tr><tr><td>metadata</td><td>Some information related to sequencing, such as time, the kit used, the sequencing flowcell, etc.</td></tr></tbody></table><p>Some readers may notice that the current signal from nanopore sequencing is somewhat similar to the audio signal in speech recognition. For example, the sound recorded by a microphone is also stored as a one-dimensional array. At the same time, the ATCG output by the basecaller is also similar to the transcript obtained by the speech recognition network (<a href=https://en.wikipedia.org/wiki/Speech_recognition>ASR</a>). Therefore, we can also consider the basecaller in nanopore sequencing as a special ASR network.</p><h2 id=architecture-of-bonito>Architecture of Bonito<a hidden class=anchor aria-hidden=true href=#architecture-of-bonito>#</a></h2><div class="callout callout-info">The code referenced in this section has listed the specific github repo and commit. Readers can refer to the source code for reading.</div><p>The following is the model architecture diagram output by torchinfo (<code>dna_r9.4.1_e8_hac@v3.3</code>, <code>state_len=4</code>), the input of the model is <code>[64,5000]</code> (batchsize, current_length)</p><pre tabindex=0><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [64, 1000, 1024]          --
├─Sequential: 1-1                        [64, 1000, 1024]          --
│    └─Convolution: 2-1                  [64, 4, 5000]             --
│    │    └─Conv1d: 3-1                  [64, 4, 5000]             24
│    │    └─Swish: 3-2                   [64, 4, 5000]             --
│    └─Convolution: 2-2                  [64, 16, 5000]            --
│    │    └─Conv1d: 3-3                  [64, 16, 5000]            336
│    │    └─Swish: 3-4                   [64, 16, 5000]            --
│    └─Convolution: 2-3                  [64, 384, 1000]           --
│    │    └─Conv1d: 3-5                  [64, 384, 1000]           117,120
│    │    └─Swish: 3-6                   [64, 384, 1000]           --
│    └─Permute: 2-4                      [1000, 64, 384]           --
│    └─LSTM: 2-5                         [1000, 64, 384]           --
│    │    └─LSTM: 3-7                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-6                         [1000, 64, 384]           --
│    │    └─LSTM: 3-8                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-7                         [1000, 64, 384]           --
│    │    └─LSTM: 3-9                    [1000, 64, 384]           1,182,720
│    └─LSTM: 2-8                         [1000, 64, 384]           --
│    │    └─LSTM: 3-10                   [1000, 64, 384]           1,182,720
│    └─LSTM: 2-9                         [1000, 64, 384]           --
│    │    └─LSTM: 3-11                   [1000, 64, 384]           1,182,720
│    └─Permute: 2-10                     [64, 1000, 384]           --
│    └─LinearCRFEncoder: 2-11            [64, 1000, 1024]          --
│    │    └─Linear: 3-12                 [64, 1000, 1024]          394,240
│    │    └─Tanh: 3-13                   [64, 1000, 1024]          --
==========================================================================================
Total params: 6,425,320
Trainable params: 6,417,640
Non-trainable params: 7,680
Total mult-adds (G): 386.11
==========================================================================================
Input size (MB): 0.64
Forward/backward pass size (MB): 877.57
Params size (MB): 12.85
Estimated Total Size (MB): 891.06
==========================================================================================
</code></pre><p><figure><img loading=lazy src=https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs13059-023-02903-2/MediaObjects/13059_2023_2903_Fig1_HTML.png alt="Fig. 1"><figcaption>Fig. 1</figcaption></figure></p><p>As shown in Figure 1 of Marcus et al.&rsquo;s <a href=https://genomebiology.biomedcentral.com/articles/10.1186/s13059-023-02903-2/>article</a>, the model structure of Bonito (and some common basecallers) is mainly divided into three parts: CNN, LSTM/RNN, etc. Encoder, and CTC/CRF, etc. Decoder.</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L150-L163>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>rnn_encoder</span><span class=p>(</span><span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>insize</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>first_conv_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>winlen</span><span class=o>=</span><span class=mi>19</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;swish&#39;</span><span class=p>,</span> <span class=n>rnn_type</span><span class=o>=</span><span class=s1>&#39;lstm&#39;</span><span class=p>,</span> <span class=n>features</span><span class=o>=</span><span class=mi>768</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>5.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>rnn</span> <span class=o>=</span> <span class=n>layers</span><span class=p>[</span><span class=n>rnn_type</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Serial</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>first_conv_size</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=n>first_conv_size</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>conv</span><span class=p>(</span><span class=mi>16</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>ks</span><span class=o>=</span><span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=n>activation</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=n>norm</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Permute</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=o>*</span><span class=p>(</span><span class=n>rnn</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=p>(</span><span class=n>num_layers</span> <span class=o>-</span> <span class=n>i</span><span class=p>)</span> <span class=o>%</span> <span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_layers</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=n>LinearCRFEncoder</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>features</span><span class=p>,</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>scale</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>blank_score</span><span class=o>=</span><span class=n>blank_score</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=n>expand_blanks</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span></code></pre></div><h3 id=configuration-file-aka-configtoml>Configuration File (a.k.a <code>config.toml</code>)<a hidden class=anchor aria-hidden=true href=#configuration-file-aka-configtoml>#</a></h3><p>Take <code>dna_r9.4.1_e8_hac@v3.3</code> (based on <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/models/configs/dna_r9.4.1@v3.1.toml>bonito/bonito/models/configs/dna_r9.4.1@v3.1.toml at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a> ) as an example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-toml data-lang=toml><span class=line><span class=cl><span class=p>[</span><span class=nx>global_norm</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c># State Length of CRF, determine how many state CRF decoder need to consider</span>
</span></span><span class=line><span class=cl><span class=nx>state_len</span> <span class=p>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>input</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>features</span> <span class=p>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>labels</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>labels</span> <span class=p>=</span> <span class=p>[</span> <span class=s2>&#34;N&#34;</span><span class=p>,</span> <span class=s2>&#34;A&#34;</span><span class=p>,</span> <span class=s2>&#34;C&#34;</span><span class=p>,</span> <span class=s2>&#34;G&#34;</span><span class=p>,</span> <span class=s2>&#34;T&#34;</span><span class=p>,]</span>
</span></span><span class=line><span class=cl><span class=c># labels of bases, N means empty state.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>qscore</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>scale</span> <span class=p>=</span> <span class=mf>0.9356</span>
</span></span><span class=line><span class=cl><span class=nx>bias</span> <span class=p>=</span> <span class=mf>-0.1721</span>
</span></span><span class=line><span class=cl><span class=c># bias factor of Q Score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>model</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>package</span> <span class=p>=</span> <span class=s2>&#34;bonito.crf&#34;</span>
</span></span><span class=line><span class=cl><span class=c># use CRF or CTC at decoder (since bonito v0.4, only CRF is valid)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>encoder</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>scale</span> <span class=p>=</span> <span class=mf>5.0</span>
</span></span><span class=line><span class=cl><span class=nx>rnn_type</span> <span class=p>=</span> <span class=s2>&#34;lstm&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>winlen</span> <span class=p>=</span> <span class=mi>19</span>
</span></span><span class=line><span class=cl><span class=nx>features</span> <span class=p>=</span> <span class=mi>384</span>
</span></span><span class=line><span class=cl><span class=nx>activation</span> <span class=p>=</span> <span class=s2>&#34;swish&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>stride</span> <span class=p>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=c># downsample stride</span>
</span></span><span class=line><span class=cl><span class=nx>blank_score</span> <span class=p>=</span> <span class=mf>2.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>basecaller</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c># config when basecalling, don&#39;t affect training</span>
</span></span><span class=line><span class=cl><span class=nx>batchsize</span> <span class=p>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl><span class=nx>chunksize</span> <span class=p>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl><span class=nx>overlap</span> <span class=p>=</span> <span class=mi>500</span>
</span></span></code></pre></div><h3 id=cnn>CNN<a hidden class=anchor aria-hidden=true href=#cnn>#</a></h3><p>After the one-dimensional array of current is input, it will first go through three convolutions for feature extraction. The implementation code of the convolution is located <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L221-L266>here</a>, it can be seen that it is a standard pytorch convolution implementation (<a href=https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html>Conv1d — PyTorch 2.4 documentation</a>), there is nothing too special. But it should be noted that in order to speed up the calculation, Bonito sets the stride to 5 in the third convolutional layer, which downsamples the signal by 5 times (5000 -> 1000). Finally, the output of the convolutional layer is <code>[64, 384, 1000]</code> (batch, channel, signal_length).</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L221-L266>bonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Convolution</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>norm</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv1d</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>winlen</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>padding</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>layers</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>activation</span><span class=p>,</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>activation</span><span class=p>)()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>norm</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>from_dict</span><span class=p>(</span><span class=n>norm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>norm</span><span class=p>,</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>layers</span><span class=p>[</span><span class=n>norm</span><span class=p>](</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>norm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>h</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>include_weights</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;insize&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>in_channels</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;size&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>out_channels</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;bias&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;winlen&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>kernel_size</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;stride&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>stride</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;padding&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>padding</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s2>&#34;activation&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>,</span> <span class=n>include_weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1>#simplify default case e.g. norm=&#34;batchnorm&#34;</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>include_weights</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span> <span class=ow>in</span> <span class=n>layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>to_dict</span><span class=p>(</span><span class=n>layers</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span><span class=p>](</span><span class=n>res</span><span class=p>[</span><span class=s2>&#34;size&#34;</span><span class=p>])):</span>
</span></span><span class=line><span class=cl>                    <span class=n>res</span><span class=p>[</span><span class=s2>&#34;norm&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>include_weights</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;W&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span></code></pre></div><h3 id=lstm>LSTM<a hidden class=anchor aria-hidden=true href=#lstm>#</a></h3><p>After feature extraction, the signal passes through a fully connected layer, and then enters the LSTM layer to learn the temporal relationship of signal features. The LSTM here is also based on the standard <a href=https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>LSTM — PyTorch 2.4 documentation</a>:</p><p><a href=https://github.com/nanoporetech/bonito/blob/91fb1408398fb3d8188621f1486281a2baa76318/bonito/nn.py#L194-L214>bonito/bonito/nn.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LSTM</span><span class=p>(</span><span class=n>RNNWrapper</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=n>reverse</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>to_dict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>include_weights</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;size&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;insize&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>input_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;bias&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;reverse&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>reverse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>include_weights</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>res</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;iW&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>weight_ih_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>input_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;sW&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>weight_hh_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;b&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>bias_ih_l0</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>hidden_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span></code></pre></div><p>The shape of the LSTM output layer is <code>[1000, 64, 384]</code> (signal_length, batch, channel)</p><h3 id=crf-encoder>CRF Encoder<a hidden class=anchor aria-hidden=true href=#crf-encoder>#</a></h3><p>After the data leaves the LSTM, it will enter a fully connected layer to output a matrix for CRF decoding. From the code, we can see that this encoder only performs a non-linear transformation on the data, and rearranges the output.</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/nn.py#L268-L299>bonito/bonito/nn.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LinearCRFEncoder</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>insize</span><span class=p>,</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>state_len</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>expand_blanks</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>permute</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span> <span class=o>=</span> <span class=n>n_base</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>state_len</span> <span class=o>=</span> <span class=n>state_len</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span> <span class=o>=</span> <span class=n>blank_score</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>expand_blanks</span> <span class=o>=</span> <span class=n>expand_blanks</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span> <span class=o>=</span> <span class=p>(</span><span class=n>n_base</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>n_base</span><span class=o>**</span><span class=n>state_len</span> <span class=k>if</span> <span class=n>blank_score</span> <span class=ow>is</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>n_base</span><span class=o>**</span><span class=p>(</span><span class=n>state_len</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>insize</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>layers</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>activation</span><span class=p>,</span> <span class=k>lambda</span><span class=p>:</span> <span class=n>activation</span><span class=p>)()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>permute</span> <span class=o>=</span> <span class=n>permute</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>permute</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=o>*</span><span class=bp>self</span><span class=o>.</span><span class=n>permute</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>scores</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>expand_blanks</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>scores</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>value</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>scores</span>
</span></span></code></pre></div><p><strong>The part with weights in the entire neural network ends here. The following CRF decoder does not include any weights.</strong> (Therefore, during training and inference, Bonito uses different decoders, which will be explained in detail later)</p><h3 id=crf-decoder>CRF Decoder<a hidden class=anchor aria-hidden=true href=#crf-decoder>#</a></h3><p>The core of the CRF Decoder is in this function:</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/basecall.py#L27-L47>bonito/bonito/crf/basecall.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=mf>100.0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Compute scores for model.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>sequence</span><span class=p>,</span> <span class=n>qstring</span><span class=p>,</span> <span class=n>moves</span> <span class=o>=</span> <span class=n>beam_search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>scores</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=n>beam_width</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=n>beam_cut</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>scale</span><span class=o>=</span><span class=n>scale</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=n>offset</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;moves&#39;</span><span class=p>:</span> <span class=n>moves</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;qstring&#39;</span><span class=p>:</span> <span class=n>qstring</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;sequence&#39;</span><span class=p>:</span> <span class=n>sequence</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></div><p>In <code>compute_scores</code>, <code>scores</code> is the matrix inferred by the aforementioned neural network, with a size of <code>[64, 1000, 1024]</code> (batch, current_length, state), $1024=4^5(4base^{4state+1})$. Then, if RNA is being sequenced, the score is reversed (this is also why the reference fasta needs to be reversed when training RNA). Finally, call <a href=https://pypi.org/project/ont-koi/>koi</a> (a non-open source CRF decoding package developed by ONT, which will be explained in detail below) <code>beam_search</code> to get <code>moves</code> (output which sampling point decoded a base, used for base sequence and current alignment reference), <code>qstring</code> (Q score string, encoded in numbers) and <code>sequence</code> (sequence, encoded in numbers).</p><h4 id=close-sourced-koi-package-and-its-open-source-alternatives>Close-sourced <code>koi</code> Package and Its Open Source Alternatives<a hidden class=anchor aria-hidden=true href=#close-sourced-koi-package-and-its-open-source-alternatives>#</a></h4><p>Since Bonito introduced CRF decoding, Bonito has encapsulated the beam search function into a close-sourced <code>ont-koi</code> package, which makes it impossible for us to understand the specific implementation of CRF decoding. But fortunately, ONT has included some CRF decoding logic in these two repos: <a href=https://github.com/davidcpage/seqdist>GitHub - davidcpage/seqdist</a> and <a href=https://github.com/nanoporetech/fast-ctc-decode>GitHub - nanoporetech/fast-ctc-decode: Blitzing Fast CTC Beam Search Decoder</a>. At the same time, ONT used the aforementioned open-source code in the old version of Bonito to build a usable <code>compute_score</code> workflow to handle the duplex part:</p><p><a href=https://github.com/nanoporetech/bonito/blob/91fb1408398fb3d8188621f1486281a2baa76318/bonito/cli/duplex.py#L217-L229>bonito/bonito/cli/duplex.py at 91fb1408398fb3d8188621f1486281a2baa76318 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span> <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>betas</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>backward_scores</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>trans</span><span class=p>,</span> <span class=n>init</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>compute_transition_probs</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>betas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;trans&#39;</span><span class=p>:</span> <span class=n>trans</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;init&#39;</span><span class=p>:</span> <span class=n>init</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>beam_search_duplex</span><span class=p>(</span><span class=n>seq1</span><span class=p>,</span> <span class=n>path1</span><span class=p>,</span> <span class=n>t1</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>seq2</span><span class=p>,</span> <span class=n>path2</span><span class=p>,</span> <span class=n>t2</span><span class=p>,</span> <span class=n>b2</span><span class=p>,</span> <span class=n>alphabet</span><span class=o>=</span><span class=s1>&#39;NACGT&#39;</span><span class=p>,</span> <span class=n>beamsize</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>pad</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span> <span class=n>T</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>env</span> <span class=o>=</span> <span class=n>build_envelope</span><span class=p>(</span><span class=n>t1</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>seq1</span><span class=p>,</span> <span class=n>path1</span><span class=p>,</span> <span class=n>t2</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>seq2</span><span class=p>,</span> <span class=n>path2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>pad</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>crf_beam_search_duplex</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>t1</span><span class=p>,</span> <span class=n>b1</span><span class=p>,</span> <span class=n>t2</span><span class=p>,</span> <span class=n>b2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>alphabet</span><span class=o>=</span><span class=n>alphabet</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>beam_size</span><span class=o>=</span><span class=n>beamsize</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>beam_cut_threshold</span><span class=o>=</span><span class=n>T</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>envelope</span><span class=o>=</span><span class=n>env</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>I have also referred to <a href=https://github.com/marcpaga/basecalling_architectures/blob/5db4957496079d19deacb01c9f4f4957f7257f49/src/classes.py#L413-L435>Marcus&rsquo;s research on Bonito CRF decoding</a>, and obtained a compute_score function implemented using ONT&rsquo;s open source code. The function mainly needs to be modified in two places, as listed below:</p><ol><li>Modify the <code>backward_scores</code> function to an open source implementation (the backward_score implementation before Bonito 0.5 can be used):</li></ol><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L63-L68>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seqdist.sparse</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>seqdist.ctc_simple</span> <span class=kn>import</span> <span class=n>logZ_cupy</span><span class=p>,</span> <span class=n>viterbi_alignments</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>seqdist.core</span> <span class=kn>import</span> <span class=n>SequenceDist</span><span class=p>,</span> <span class=n>Max</span><span class=p>,</span> <span class=n>Log</span><span class=p>,</span> <span class=n>semiring</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>backward_scores</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>S</span><span class=p>:</span> <span class=n>semiring</span><span class=o>=</span><span class=n>Log</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>Ms</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>beta_T</span> <span class=o>=</span> <span class=n>Ms</span><span class=o>.</span><span class=n>new_full</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_base</span><span class=o>**</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>state_len</span><span class=p>)),</span> <span class=n>S</span><span class=o>.</span><span class=n>one</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>seqdist</span><span class=o>.</span><span class=n>sparse</span><span class=o>.</span><span class=n>bwd_scores_cupy</span><span class=p>(</span><span class=n>Ms</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>idx</span><span class=p>,</span> <span class=n>beta_T</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>K</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><ol start=2><li>Modify the <code>compute_scores</code> function, remember to import the corresponding packages:</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fast_ctc_decode</span> <span class=kn>import</span> <span class=n>crf_greedy_search</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_scores</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch</span><span class=p>,</span> <span class=n>beam_width</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>beam_cut</span><span class=o>=</span><span class=mf>100.0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>offset</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>blank_score</span><span class=o>=</span><span class=mf>2.0</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Compute scores for model.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span> <span class=k>if</span> <span class=n>half_supported</span><span class=p>()</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reverse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>reverse_complement</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># switch dim 1 &amp; 2</span>
</span></span><span class=line><span class=cl>        <span class=n>scores_pad</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># pad score</span>
</span></span><span class=line><span class=cl>        <span class=n>n_base</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>n_base</span>
</span></span><span class=line><span class=cl>        <span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>scores_pad</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>scores_pad</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>scores_pad</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=n>n_base</span><span class=p>,</span> <span class=n>n_base</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span><span class=o>=</span><span class=n>blank_score</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>betas</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>backward_scores</span><span class=p>(</span><span class=n>scores_pad</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>trans</span><span class=p>,</span> <span class=n>init</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>compute_transition_probs</span><span class=p>(</span><span class=n>scores_pad</span><span class=p>,</span> <span class=n>betas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>trans</span> <span class=o>=</span> <span class=n>trans</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>init</span> <span class=o>=</span> <span class=n>init</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># offload</span>
</span></span><span class=line><span class=cl>        <span class=n>tracebacks</span> <span class=o>=</span> <span class=n>trans</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>init</span> <span class=o>=</span> <span class=n>init</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>seq_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>qstring_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>moves_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N</span><span class=p>,</span> <span class=n>T</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>uint8</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>tracebacks_batch</span> <span class=o>=</span> <span class=n>tracebacks</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>  <span class=c1># (T, 256, 5)</span>
</span></span><span class=line><span class=cl>            <span class=n>init_batch</span> <span class=o>=</span> <span class=n>init</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>  <span class=c1># (256,)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># greedy decode, cef_beam_search dont output qstring</span>
</span></span><span class=line><span class=cl>            <span class=n>seq_batch</span><span class=p>,</span> <span class=n>path_batch</span> <span class=o>=</span> <span class=n>crf_greedy_search</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>network_output</span><span class=o>=</span><span class=n>tracebacks_batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>init_state</span><span class=o>=</span><span class=n>init_batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>alphabet</span><span class=o>=</span><span class=s2>&#34;NACGT&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qstring</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qscale</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>qbias</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># re-encode</span>
</span></span><span class=line><span class=cl>            <span class=n>seq_batch_str</span> <span class=o>=</span> <span class=n>seq_batch</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>seq_batch</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_batch_str</span> <span class=o>=</span> <span class=n>seq_batch</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>seq_batch</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>seq_as_numbers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>frombuffer</span><span class=p>(</span><span class=n>seq_batch_str</span><span class=o>.</span><span class=n>encode</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_as_numbers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>frombuffer</span><span class=p>(</span><span class=n>qstring_batch_str</span><span class=o>.</span><span class=n>encode</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>seq_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>seq_as_numbers</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>path_batch</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>            <span class=n>qstring_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>qstring_as_numbers</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>path_batch</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>            <span class=n>moves_tensor</span><span class=p>[</span><span class=n>batch_idx</span><span class=p>,</span> <span class=n>path_batch</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;qstring&#39;</span><span class=p>:</span> <span class=n>qstring_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;sequence&#39;</span><span class=p>:</span> <span class=n>seq_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;moves&#39;</span><span class=p>:</span> <span class=n>moves_tensor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></div><div class="callout callout-warning">It should be noted that the open-source implementation here has replaced <code>beam_search</code> with <code>crf_greedy_search</code>. <strong>Therefore, the accuracy of the basecaller may be slightly reduced.</strong> However, according to my tests, the accuracy only decreases by about 0.3%, which I think is not perfect but acceptable.</div><p><em>At this point, the obtained <code>qstring</code>, <code>sequence</code> is a matrix with a length of <code>current_length</code>. Some indices are 0 (indicating that no new bases were decoded at this position), and the remaining indices are numbers (number-encoded ATCG bases or q string scores).</em></p><h3 id=stitching-basecaller-results-and-outputting-characters>Stitching Basecaller Results and Outputting Characters<a hidden class=anchor aria-hidden=true href=#stitching-basecaller-results-and-outputting-characters>#</a></h3><p>Due to the limited window size of the neural network, when encountering long sequences of current, the current will be split into short sequences according to the <code>chunksize</code> and <code>overlap</code> given in the network configuration. Therefore, after completing the decoding, the obtained <code>qstring</code>, <code>sequence</code> and <code>moves</code> need to be re-stitched together according to read_id by the <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/basecall.py#L13-L14>stitch_results</a> function.</p><p>After stitching, the sequence will be decoded back to the base sequence/Q Score through decoding functions such as <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L105-L106>path_to_str</a>. Finally, after formatting, it can be output as fastq, or after going through <a href=https://github.com/lh3/minimap2/blob/master/python/mappy.pyx>mappy</a> once, it can be output as an aligned sam/bam file.</p><hr><h2 id=training-bonito>Training Bonito<a hidden class=anchor aria-hidden=true href=#training-bonito>#</a></h2><h3 id=dataset-structure>Dataset Structure<a hidden class=anchor aria-hidden=true href=#dataset-structure>#</a></h3><p>Referencing the official documentation of Bonito 0.8.1, we need at least three <code>.npy</code> files to construct a training basecaller dataset (assuming that the length of each current segment used during training is <code>chunksize</code>). Referencing Bonito&rsquo;s <a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/cli/download.py#L130-L131>download.py</a>, Bonito currently provides three training datasets, listed below:</p><table><thead><tr><th>Url</th><th>flowcell</th></tr></thead><tbody><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r9.4.1_v0.zip</a></td><td>dna_r9.4.1</td></tr><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_dna_r10.4.1_v0.zip</a></td><td>dna_r10.4.1</td></tr><tr><td><a href=https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip>https://cdn.oxfordnanoportal.com/software/analysis/bonito/example_data_rna004_v0.zip</a></td><td>rna004</td></tr></tbody></table><p>Each downloaded and decompressed dataset contains three <code>.npy</code> files:</p><table><thead><tr><th>Filename</th><th>Shape</th><th>Purpose</th></tr></thead><tbody><tr><td>references.npy</td><td>(data_length, max_len_of_reference) <code>uint8</code></td><td>Stores the sequence corresponding to each signal chunk, encoded using rules such as <code>{'A': 1, 'C': 2, 'G': 3, 'T': 4}</code> for ATCG, with the remaining positions padded with 0</td></tr><tr><td>reference_lengths.npy</td><td>(data_length,) <code>uint8</code></td><td>Stores the <strong>length</strong> of the sequence corresponding to each signal chunk (the part not padded with 0)</td></tr><tr><td>chunks.npy</td><td>(data_length, chunksize) <code>float32</code></td><td>Stores the current signal of each signal chunk</td></tr></tbody></table><p>Optionally, the dataset folder can also contain a folder named <code>validation_sets</code>. If this folder exists, the <code>references.npy</code>, <code>reference_lengths.npy</code>, and <code>chunks.npy</code> inside it will be used as the validation set.</p><h3 id=training-related-commands>Training-related Commands<a hidden class=anchor aria-hidden=true href=#training-related-commands>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># bonito train</span>
</span></span><span class=line><span class=cl>positional arguments:
</span></span><span class=line><span class=cl>  training_directory
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>optional arguments:
</span></span><span class=line><span class=cl>  -h, --help            show this <span class=nb>help</span> message and <span class=nb>exit</span>
</span></span><span class=line><span class=cl>  --config CONFIG
</span></span><span class=line><span class=cl>  --pretrained PRETRAINED
</span></span><span class=line><span class=cl>  --directory DIRECTORY
</span></span><span class=line><span class=cl>  --device DEVICE
</span></span><span class=line><span class=cl>  --lr LR
</span></span><span class=line><span class=cl>  --seed SEED
</span></span><span class=line><span class=cl>  --epochs EPOCHS
</span></span><span class=line><span class=cl>  --batch BATCH
</span></span><span class=line><span class=cl>  --chunks CHUNKS
</span></span><span class=line><span class=cl>  --valid-chunks VALID_CHUNKS
</span></span><span class=line><span class=cl>  --no-amp
</span></span><span class=line><span class=cl>  -f, --force
</span></span><span class=line><span class=cl>  --restore-optim
</span></span><span class=line><span class=cl>  --nondeterministic
</span></span><span class=line><span class=cl>  --save-optim-every SAVE_OPTIM_EVERY
</span></span><span class=line><span class=cl>  --grad-accum-split GRAD_ACCUM_SPLIT
</span></span><span class=line><span class=cl>  --quantile-grad-clip
</span></span><span class=line><span class=cl>  --num-workers NUM_WORKERS
</span></span></code></pre></div><h3 id=loss-function-calculation-during-training>Loss Function Calculation During Training<a hidden class=anchor aria-hidden=true href=#loss-function-calculation-during-training>#</a></h3><p>Unlike the CRF used during inference, Bonito does not use the previously mentioned <code>compute_score</code> function as the decoder and loss function during training.</p><p><a href=https://github.com/nanoporetech/bonito/blob/0c7fcceeeca16e300ba427d737282b33d3cb8ec9/bonito/crf/model.py#L196-L199>bonito/bonito/crf/model.py at 0c7fcceeeca16e300ba427d737282b33d3cb8ec9 · nanoporetech/bonito · GitHub</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>posteriors</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span> <span class=o>+</span> <span class=mf>1e-8</span>
</span></span><span class=line><span class=cl>        <span class=n>tracebacks</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>viterbi</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>log</span><span class=p>())</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>int16</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>seqdist</span><span class=o>.</span><span class=n>path_to_str</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>tracebacks</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()]</span>
</span></span></code></pre></div><p>Instead, it uses seqdist&rsquo;s viterbi search to directly obtain the sequence, and then compares it with the standard reference sequence to obtain an accuracy.</p><h3 id=training-command>Training Command<a hidden class=anchor aria-hidden=true href=#training-command>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>bonito train <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>--config config.toml <span class=se>\ </span><span class=c1># The model config mentioned earlier, chunksize, etc., will be automatically read from the dataset</span>
</span></span><span class=line><span class=cl>--device cuda:0 <span class=se>\ </span><span class=c1># GPU</span>
</span></span><span class=line><span class=cl>--epochs <span class=m>5</span> <span class=c1># epoch</span>
</span></span><span class=line><span class=cl>--lr 5e-4 <span class=se>\ </span><span class=c1># learning rate</span>
</span></span><span class=line><span class=cl>--batch <span class=m>96</span> <span class=se>\ </span><span class=c1># batchsize</span>
</span></span><span class=line><span class=cl>--pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0 <span class=se>\ </span><span class=c1># Existing model, you can select from the models provided by ONT, or pass in the directory where other models are located</span>
</span></span><span class=line><span class=cl>--directory dataset_dir/  <span class=se>\ </span><span class=c1># Folder containing chunks.npy, etc.</span>
</span></span><span class=line><span class=cl>model_dir/
</span></span></code></pre></div><p>This command initiates the training process. Let&rsquo;s break down the key components:</p><ul><li><code>bonito train</code>: This is the main command to start the training of a Bonito model.</li><li><code>--config config.toml</code>: This specifies the configuration file for the model. This file defines various parameters like the network architecture, number of states for CRF, input/label configurations, learning rate, and more. The <code>config.toml</code> file was described in detail earlier.</li><li><code>--device cuda:0</code>: This argument tells Bonito to use the first CUDA-enabled GPU (if available). If you have multiple GPUs, you can specify a different ID (e.g., <code>cuda:1</code>). If you want to train on CPU, you can use <code>cpu</code> as an argument, but training on GPU will be significantly faster.</li><li><code>--epochs 5</code>: This sets the number of training epochs, indicating how many times the entire training dataset will be passed through the model.</li><li><code>--lr 5e-4</code>: This sets the learning rate for the optimizer. A lower learning rate can result in finer tuning of the weights but may also require more training epochs.</li><li><code>--batch 96</code>: This specifies the batch size, i.e., the number of training examples that the model will process in each iteration. Larger batch sizes can utilize GPU resources more efficiently, but may also lead to memory issues, particularly with smaller GPUs.</li><li><code>--pretrained dna_r10.4.1_e8.2_400bps_hac@v5.0.0</code>: This crucial parameter specifies the model that will be used as a starting point. This leverages transfer learning, enabling you to train more quickly and effectively. You can use ONT&rsquo;s pre-trained models, like the example provided (<code>dna_r10.4.1_e8.2_400bps_hac@v5.0.0</code>) or point to a custom pre-trained model.</li><li><code>--directory dataset_dir/</code>: This points to the directory containing the training dataset. Bonito expects the training data to be in the format explained in the &ldquo;Dataset Structure&rdquo; section. It will automatically load the <code>chunks.npy</code>, <code>references.npy</code>, and <code>reference_lengths.npy</code> from the provided directory, and potentially validation data from the <code>validation_sets</code> subfolder.</li><li><code>model_dir/</code>: Finally, <code>model_dir/</code> is the directory where the trained model (including model weights) and training checkpoints will be saved.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.sparktour.me/en/tags/bonito/>Bonito</a></li></ul><nav class=paginav><a class=prev href=https://blog.sparktour.me/en/posts/2024/10/03/2024-summer-usa-travel-notes/><span class=title>« Prev</span><br><span>USA Travelogue</span>
</a><a class=next href=https://blog.sparktour.me/en/posts/2024/08/01/2024-korea-trip/><span class=title>Next »</span><br><span>Korea Trip: A Typical Northeast Asian Metropolis</span></a></nav></footer><div class="callout callout-default"><img src=https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.svg alt="CC BY-NC-SA 4.0" style=width:88px;height:31px><p style=font-size:12px>Licensed Under <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener>CC BY-NC-SA 4.0</a></p><p style=font-size:12px>Post Link: <a href=https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/ target=_blank rel=noopener>https://blog.sparktour.me/en/posts/2024/09/25/a-look-at-nanopore-basecaller-bonito/</a></p></div><script src=https://s4.zstatic.net/ajax/libs/disqusjs/3.0.2/disqusjs.es2015.umd.min.js crossorigin=anonymous></script><div id=disqusjs></div><script>const disqusjs=new DisqusJS({shortname:"sparktour",siteName:"",identifier:"",url:"",title:"",api:"https://disqus.com/api/",apikey:"QhJnXpS5igyHkjYQ91XYC4dSAuEJYAEsHX8hjLrRc1HU9AApOHLrqkwwIp2sKOLk",admin:"",adminLabel:""});disqusjs.render(document.getElementById("disqusjs"))</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.sparktour.me/en/>Sparktour’s Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>